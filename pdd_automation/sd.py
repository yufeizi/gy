#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ï¿½æ‰‹åŠ¨æŠ“å–æ¨¡å— - æŒç»­ç›‘æ§ç‰ˆæœ¬
ç”¨äºåœ¨UIï¿½ é›†æˆï¼Œå®ç°ä¸€ç›´åœ¨çº¿è‡ªåŠ¨æŠ“å–
"""

import os
import sys
import json
import time
import asyncio
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List

class ManualDataExtractor:
    """æ‰‹åŠ¨æ•°æ®æŠ“å–å™¨ - æŒç»­ç›‘æ§ç‰ˆæœ¬"""
    
    def __init__(self, browser_id: str, ui_log_callback=None):
        self.browser_id = browser_id
        self.is_manual_mode = False
        self.is_monitoring = False
        self.debug_port = None
        self.save_path = None
        self.last_extracted_url = None
        self.monitor_thread = None
        self.ui_log_callback = ui_log_callback  # UIæ—¥å¿—å›è°ƒå‡½æ•°
        
        # å†…å­˜ç›‘æ§ç›¸å…³
        self.memory_check_interval = 60  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡å†…å­˜
        self.last_memory_check = time.time()
        self.memory_threshold = 500 * 1024 * 1024  # 500MBå†…å­˜é˜ˆå€¼
        
        # è®¾ç½®ä¿å­˜è·¯å¾„
        self._setup_save_path()
        
        # ğŸ”¥ æ–°å¢ï¼šCSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½åˆå§‹åŒ–
        self._init_csv_functionality()
    
    def _check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œè¶…è¿‡é˜ˆå€¼è‡ªåŠ¨æ¸…ç†"""
        current_time = time.time()
        
        # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡å†…å­˜
        if current_time - self.last_memory_check < self.memory_check_interval:
            return
        
        try:
            import psutil
            import gc
            
            # è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            print(f"[å†…å­˜ç›‘æ§] å½“å‰å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB")
            
            # å¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œæ‰§è¡Œæ¸…ç†
            if memory_info.rss > self.memory_threshold:
                print(f"[å†…å­˜ç›‘æ§] âš ï¸ å†…å­˜ä½¿ç”¨è¶…è¿‡{self.memory_threshold/1024/1024:.0f}MBï¼Œå¼€å§‹æ¸…ç†...")
                
                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()
                
                # æ¸…ç†å¯èƒ½çš„ç¼“å­˜æ•°æ®
                if hasattr(self, 'last_extracted_data'):
                    delattr(self, 'last_extracted_data')
                
                print(f"[å†…å­˜ç›‘æ§] âœ… å†…å­˜æ¸…ç†å®Œæˆ")
            
            self.last_memory_check = current_time
            
        except ImportError:
            # psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜ç›‘æ§
            pass
        except Exception as e:
            print(f"[å†…å­˜ç›‘æ§] âŒ å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")
    
    def _setup_save_path(self):
        """è®¾ç½®ä¿å­˜è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨ä¸»ç›®å½•çš„detailsæ–‡ä»¶å¤¹"""
        # å°è¯•æ‰¾åˆ°ä¸»ç›®å½•çš„detailsæ–‡ä»¶å¤¹
        current_dir = Path(__file__).parent
        main_details = current_dir.parent.parent / "details"
        
        if main_details.exists():
            self.save_path = str(main_details)
            print(f"[è·¯å¾„è®¾ç½®] ä½¿ç”¨ä¸»ç›®å½•details: {self.save_path}")
        else:
            # å›é€€åˆ°æµè§ˆå™¨ç‰¹å®šçš„detailsæ–‡ä»¶å¤¹
            browser_details = current_dir / "details"
            browser_details.mkdir(exist_ok=True)
            self.save_path = str(browser_details)
            print(f"[è·¯å¾„è®¾ç½®] ä½¿ç”¨æµè§ˆå™¨details: {self.save_path}")
    
    def _get_debug_port(self) -> Optional[int]:
        """è·å–è°ƒè¯•ç«¯å£"""
        try:
            # ä»é…ç½®æ–‡ä»¶è·å–è°ƒè¯•ç«¯å£
            config_path = Path(__file__).parent / "config_api.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    port = config.get('browser_info', {}).get('debug_port')
                    if port:
                        self.debug_port = port
                        return port
            
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£
            return 53484
            
        except Exception as e:
            return None
    
    def start_manual_mode(self):
        """å¯åŠ¨æ‰‹åŠ¨æŠ“å–æ¨¡å¼"""
        self.is_manual_mode = True
        print(f"âœ… æ‰‹åŠ¨è§£æåŠŸèƒ½å¼€å¯")
        
        # å¯åŠ¨æŒç»­ç›‘æ§
        self.start_continuous_monitoring()
    
    def start_continuous_monitoring(self):
        """å¯åŠ¨æŒç»­ç›‘æ§"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯ - ä¸€ç›´è¿è¡Œ"""
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            while self.is_monitoring:
                try:
                    # æ‰§è¡Œä¸€æ¬¡æŠ“å–æ£€æŸ¥
                    loop.run_until_complete(self._check_and_extract())
                    
                    # å†…å­˜ç›‘æ§æ£€æŸ¥
                    self._check_memory_usage()
                    
                    # ç­‰å¾…0.5ç§’åå†æ¬¡æ£€æŸ¥ï¼ˆæé«˜å“åº”é€Ÿåº¦ï¼‰
                    time.sleep(0.5)
                    
                except Exception as e:
                    print(f"[ç›‘æ§å¾ªç¯] âŒ æŠ“å–æ£€æŸ¥å¼‚å¸¸: {e}")
                    # å‡ºé”™åç­‰å¾…1ç§’ï¼Œä½†ç»§ç»­å¾ªç¯
                    time.sleep(1)

        except Exception as e:
            print(f"[ç›‘æ§å¾ªç¯] âŒ ç›‘æ§å¾ªç¯ä¸¥é‡å¼‚å¸¸: {e}")
        finally:
            try:
                loop.close()
                print("[ç›‘æ§å¾ªç¯] âœ… äº‹ä»¶å¾ªç¯å·²å…³é—­")
            except:
                pass
    
    async def _check_and_extract(self):
        """æ£€æŸ¥å½“å‰é¡µé¢å¹¶æŠ“å–"""
        try:
            from playwright.async_api import async_playwright
            
            async with async_playwright() as playwright:
                debug_port = self._get_debug_port()
                if not debug_port:
                    return False
                
                browser = await playwright.chromium.connect_over_cdp(f"http://127.0.0.1:{debug_port}")
                
                if browser.contexts and browser.contexts[0].pages:
                    page = browser.contexts[0].pages[0]
                    current_url = page.url
                    
                    # ğŸ”¥ æ–°å¢ï¼šå®šæœŸå†…å­˜æ¸…ç†ï¼ˆæ¯10æ¬¡æ£€æŸ¥æ¸…ç†ä¸€æ¬¡ï¼‰
                    if not hasattr(self, '_check_count'):
                        self._check_count = 0
                    self._check_count += 1
                    
                    if self._check_count % 20 == 0:  # æ¯20æ¬¡æ£€æŸ¥æ¸…ç†ä¸€æ¬¡ï¼ˆæ¯10ç§’ï¼‰
                        print(f"[MEMORY] å®šæœŸå†…å­˜æ¸…ç† (ç¬¬{self._check_count}æ¬¡æ£€æŸ¥)")
                        await self._clean_browser_memory(page)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¯¦æƒ…é¡µ
                    if self._is_detail_page(current_url):
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æŠ“å–è¿‡è¿™ä¸ªé¡µé¢
                        if current_url != self.last_extracted_url:
                            success = await self.manual_extract_data(page)
                            if success:
                                self.last_extracted_url = current_url
                                return True
                        return False
                    else:
                        return False
                        
                await browser.close()
                return False

        except Exception as e:
            print(f"[æ£€æŸ¥] å‡ºé”™: {e}")
            return False

    async def _clean_browser_memory(self, page):
        """æ¸…ç†æµè§ˆå™¨å†…å­˜"""
        try:
            await page.evaluate("""
                (() => {
                    try {
                        // å¼ºåˆ¶åƒåœ¾å›æ”¶
                        if (window.gc) window.gc();
                        
                        // æ¸…é™¤æ‰€æœ‰å®šæ—¶å™¨
                        const highestTimeoutId = setTimeout(";");
                        for (let i = 0; i < highestTimeoutId; i++) {
                            clearTimeout(i);
                            clearInterval(i);
                        }
                        
                        // æ¸…é™¤å¤§å‹æ•°æ®ç»“æ„
                        if (window.rawData) window.rawData = null;
                        if (window.historyDataForSave) window.historyDataForSave = null;
                        if (window.latest20DataForSave) window.latest20DataForSave = null;
                        
                        // æ¸…é™¤äº‹ä»¶ç›‘å¬å™¨ç¼“å­˜
                        const elements = document.querySelectorAll('*');
                        elements.forEach(el => {
                            if (el._listeners) el._listeners = null;
                            if (el._events) el._events = null;
                        });
                        
                        // æ¸…é™¤å›¾ç‰‡ç¼“å­˜
                        const images = document.querySelectorAll('img');
                        images.forEach(img => {
                            if (img.src && !img.src.includes('login') && !img.src.includes('auth') && !img.src.includes('token')) {
                                img.src = '';
                                img.removeAttribute('src');
                            }
                        });
                        
                        // æ¸…é™¤å¯èƒ½çš„ç¼“å­˜å¯¹è±¡ï¼ˆä¿ç•™ç™»å½•ç›¸å…³ï¼‰
                        if (window.caches) {
                            caches.keys().then(names => {
                                names.forEach(name => {
                                    // ä¸åˆ é™¤åŒ…å«loginã€authã€tokençš„ç¼“å­˜
                                    if (!name.includes('login') && !name.includes('auth') && !name.includes('token')) {
                                        caches.delete(name);
                                    }
                                });
                            });
                        }
                        
                        // âš ï¸ é‡è¦ï¼šä¸æ¸…é™¤localStorageå’ŒsessionStorageï¼Œä¿ç•™ç™»å½•è´¦å·ä¿¡æ¯
                        // localStorageå’ŒsessionStorageåŒ…å«ç™»å½•tokenï¼Œç»å¯¹ä¸èƒ½æ¸…é™¤
                        console.log('å†…å­˜æ¸…ç†å®Œæˆï¼ˆä¿ç•™ç™»å½•ä¿¡æ¯ï¼‰');
                        
                        return true;
                    } catch (e) {
                        console.error('å†…å­˜æ¸…ç†å¤±è´¥:', e);
                        return false;
                    }
                })()
            """)
            print("[MEMORY] æµè§ˆå™¨å†…å­˜æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"[WARNING] æµè§ˆå™¨å†…å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def _is_detail_page(self, url):
        """åˆ¤æ–­æ˜¯å¦æ˜¯è¯¦æƒ…é¡µ"""
        # åªæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«goods_id=ï¼Œæœ‰å°±æ˜¯è¯¦æƒ…é¡µï¼Œæ²¡æœ‰å°±ä¸æ˜¯è¯¦æƒ…é¡µ
        return "goods_id=" in url

    def _extract_goods_id(self, raw_data: Dict) -> Optional[str]:
        """ä»rawDataä¸­æå–å•†å“ID"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            paths = [
                ['rawData', 'store', 'initDataObj', 'goods', 'goodsID'],
                ['rawData', 'store', 'initDataObj', 'goods', 'goodsId'],
                ['rawData', 'store', 'initDataObj', 'queries', 'goods_id'],
                ['rawData', 'goods', 'goodsID'],
                ['rawData', 'goods', 'goodsId']
            ]

            for path in paths:
                try:
                    value = raw_data
                    for key in path:
                        value = value[key]
                    if value:
                        return str(value)
                except (KeyError, TypeError):
                    continue

            # ä»URLä¸­æå–
            url = raw_data.get('url', '')
            if url:
                import re
                patterns = [
                    r'goods_id[=\/](\d+)',
                    r'\/g\/(\d+)',
                    r'\/goods\/(\d+)',
                    r'\/(\d{10,})'
                ]
                for pattern in patterns:
                    match = re.search(pattern, url)
                    if match:
                        return match.group(1)

                return None
        except Exception as e:
            print(f"[è­¦å‘Š] æå–å•†å“IDå¤±è´¥: {e}")
            return None

    async def manual_extract_data(self, page) -> bool:
        """æ‰‹åŠ¨æŠ“å–æ•°æ®"""
        try:
            # ç­‰å¾…é¡µé¢åŸºæœ¬åŠ è½½å®Œæˆ
            await page.wait_for_load_state('domcontentloaded')

            # ç­‰å¾…window.rawDataå¯ç”¨ï¼ˆå‡å°‘è¶…æ—¶æ—¶é—´ï¼Œæé«˜é€Ÿåº¦ï¼‰
            try:
                await page.wait_for_function('''
                    () => window.rawData &&
                          window.rawData.store &&
                          window.rawData.store.initDataObj
                ''', timeout=2000)  # å‡å°‘åˆ°2ç§’
            except Exception as e:
                # è¶…æ—¶åç»§ç»­å°è¯•è·å–æ•°æ®
                pass

            # æŠ“å–å®Œæ•´çš„rawData
            raw_data = await page.evaluate('''
                () => {
                    if (!window.rawData) {
                        return null;
                    }

                    // æ·±åº¦å¤åˆ¶rawDataï¼Œé¿å…å¼•ç”¨é—®é¢˜
                    function deepClone(obj, maxDepth = 15, currentDepth = 0) {
                        if (currentDepth >= maxDepth) return '[æ·±åº¦é™åˆ¶]';
                        if (obj === null || typeof obj !== 'object') return obj;

                        if (Array.isArray(obj)) {
                            return obj.slice(0, 100).map(item => deepClone(item, maxDepth, currentDepth + 1));
                        }

                        const result = {};
                        let count = 0;
                        for (const key in obj) {
                            if (count >= 200) break; // é™åˆ¶æ¯å±‚æœ€å¤š200ä¸ªå±æ€§
                            if (obj.hasOwnProperty(key)) {
                                result[key] = deepClone(obj[key], maxDepth, currentDepth + 1);
                                count++;
                            }
                        }
                        return result;
                    }

                    const clonedData = deepClone(window.rawData);

                    return {
                        url: window.location.href,
                        title: document.title,
                        timestamp: new Date().toISOString(),
                        rawData: clonedData,
                        extractTime: new Date().toISOString().replace('T', ' ').substring(0, 19)
                    };
                }
            ''')

            if not raw_data or not raw_data.get('rawData'):
                return False

            # ä¿å­˜æŠ“å–çš„æ•°æ®ç”¨äºåç»­ä¿å­˜
            self.last_extracted_data = raw_data
            
            # æå–å•†å“ID
            goods_id = self._extract_goods_id(raw_data)
            if goods_id:
                self.last_goods_id = goods_id
            else:
                self.last_goods_id = f"unknown_{int(time.time())}"
            
            # åŠ å¯†å‹ç¼©å¹¶ä¸Šä¼ åˆ°æœåŠ¡å™¨
            success = await self._process_and_upload_data(raw_data)
            
            return success

        except Exception as e:
            print(f"[æŠ“å–] å¤±è´¥: {e}")
            return False

    async def _process_and_upload_data(self, raw_data) -> bool:
        """å¤„ç†å’Œä¸Šä¼ æ•°æ®"""
        try:
            # 1. åŠ å¯†å‹ç¼©
            encrypted_data = self.encrypt_compress_for_cloud(raw_data)
            if not encrypted_data:
                return False

            # 2. ä¸Šä¼ åˆ°æœåŠ¡å™¨
            upload_success = await self.upload_to_server(encrypted_data['encrypted_data'], self.last_goods_id)
            if not upload_success:
                return False
            
            # 3. ä»æœåŠ¡å™¨ä¸‹è½½å¹¶ä¿å­˜
            download_success = await self.download_and_save_from_server(self.last_goods_id, raw_data)
            if not download_success:
                return False
            
            return True

        except Exception as e:
            print(f"[å¤„ç†] å¤±è´¥: {e}")
            return False

    def encrypt_compress_for_cloud(self, raw_data: Dict) -> Optional[Dict]:
        """
        åŠ å¯†å‹ç¼©æ•°æ®ç”¨äºäº‘ç«¯ä¸Šä¼ 

        Args:
            raw_data: åŸå§‹æ•°æ®

        Returns:
            åŒ…å«åŠ å¯†æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            import json
            import base64
            import gzip

            # 1. è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            json_str = json.dumps(raw_data, ensure_ascii=False, separators=(',', ':'))
            original_size = len(json_str.encode('utf-8'))

            # 2. å‹ç¼©æ•°æ®
            compressed_data = gzip.compress(json_str.encode('utf-8'))
            compressed_size = len(compressed_data)

            # 3. Base64ç¼–ç ï¼ˆæ¨¡æ‹ŸåŠ å¯†ï¼‰
            encrypted_data = base64.b64encode(compressed_data).decode('utf-8')
            final_size = len(encrypted_data.encode('utf-8'))

            # 4. è®¡ç®—å‹ç¼©ç‡
            compression_ratio = f"{(1 - final_size / original_size) * 100:.1f}%"

            print(f"[åŠ å¯†] å®Œæˆ: {compression_ratio}")

            return {
                'encrypted_data': encrypted_data,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'final_size': final_size,
                'compression_ratio': compression_ratio
            }

        except Exception as e:
            print(f"[é”™è¯¯] æ•°æ®åŠ å¯†å‹ç¼©å¤±è´¥: {e}")
            return None

    async def upload_to_server(self, encrypted_data: str, goods_id: str) -> bool:
        """
        ä¸Šä¼ åŠ å¯†æ•°æ®åˆ°æœåŠ¡å™¨

        Args:
            encrypted_data: åŠ å¯†åçš„æ•°æ®
            goods_id: å•†å“ID

        Returns:
            æ˜¯å¦ä¸Šä¼ æˆåŠŸ
        """
        try:
            import asyncio
            # ğŸ”¥ æ¨¡æ‹Ÿä¸Šä¼ åˆ°æœåŠ¡å™¨
            await asyncio.sleep(0.1)  # å‡å°‘å»¶è¿Ÿï¼Œæé«˜é€Ÿåº¦
            return True

        except Exception as e:
            print(f"[é”™è¯¯] ä¸Šä¼ å¤±è´¥: {e}")
            return False

    async def download_and_save_from_server(self, goods_id: str, original_data: dict = None) -> bool:
        """
        ä»çœŸå®UbuntuæœåŠ¡å™¨ä¸‹è½½å‹ç¼©JSONæ•°æ®å¹¶ä¿å­˜ä¸ºTXTæ–‡æ¡£åˆ°detailsç›®å½•

        æµç¨‹ï¼šä¸Šä¼ åˆ°æœåŠ¡å™¨ â†’ æœåŠ¡å™¨åŠ å¯†å‹ç¼©ä¿å­˜ â†’ ä»æœåŠ¡å™¨ä¸‹è½½å‹ç¼©æ•°æ® â†’ ä¿å­˜ä¸ºTXTæ–‡æ¡£åˆ°detailsç›®å½•

        Args:
            goods_id: å•†å“ID
            original_data: åŸå§‹æ•°æ®ï¼ˆç”¨äºé¢„å”®æ£€æµ‹ã€CSVå­—æ®µæå–å’Œå•†å“åç§°æå–ï¼Œä¸ä¿å­˜åŸå§‹æ•°æ®ï¼‰

        Returns:
            æ˜¯å¦ä¸‹è½½ä¿å­˜æˆåŠŸ
        """
        try:
            import aiohttp
            import asyncio
            import json
            from pathlib import Path
            
            # é¢„å”®æ£€æµ‹ - æ£€æµ‹åˆ°click_noticeå­—æ®µåˆ™è·³è¿‡ä¿å­˜
            if original_data:
                presale_info = self._extract_presale_info(original_data)
                if presale_info:  # å¦‚æœå­˜åœ¨click_noticeå­—æ®µå†…å®¹ï¼Œåˆ™è·³è¿‡ä¿å­˜
                    print(f"ğŸ—‘ï¸  æ£€æµ‹åˆ°éƒ¨åˆ†é¢„å”®å•†å“({goods_id})ï¼Œè·³è¿‡å¤„ç†")
                    return True

            # æœåŠ¡å™¨é…ç½®ï¼ˆä»config_api.jsonè¯»å–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
            server_url = "http://localhost:8888"
            try:
                config_path = Path(__file__).parent / "config_api.json"
                if config_path.exists():
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                        cloud_server = config.get('cloud_server', {})
                        server_url = cloud_server.get('server_url', server_url)
            except Exception:
                pass
            
            # ä»æœåŠ¡å™¨ä¸‹è½½å‹ç¼©æ•°æ®
            timeout = aiohttp.ClientTimeout(total=30)  # 30ç§’è¶…æ—¶
            async with aiohttp.ClientSession(timeout=timeout) as session:
                download_data = {'filename': f'{goods_id}.json'}
                async with session.post(f"{server_url}/download", json=download_data) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('status') == 'success':
                            # è·å–è§£å¯†åçš„æ•°æ®ï¼ˆæœåŠ¡å™¨å·²ç»è§£å¯†äº†ï¼‰
                            data = result.get('data', {})
                            
                            if not data:
                                return False
                            
                            # ç¡®ä¿detailsç›®å½•å­˜åœ¨
                            current_file_dir = os.path.dirname(os.path.abspath(__file__))
                            project_root = current_file_dir
                            while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                                parent = os.path.dirname(project_root)
                                if parent == project_root:
                                    break
                                project_root = parent
                            
                            details_dir = Path(project_root) / "details"
                            details_dir.mkdir(exist_ok=True)
                            
                            # ä¿å­˜æ•°æ®ä¸ºTXTæ–‡æ¡£ï¼ˆä»¥å•†å“IDå‘½åï¼‰
                            txt_file = details_dir / f"{goods_id}.txt"
                            with open(txt_file, 'w', encoding='utf-8') as f:
                                json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
                                f.write(json_str)
                            
                            # æå–å•†å“åç§°ç”¨äºæ—¥å¿—æ˜¾ç¤º
                            goods_name = "æœªçŸ¥å•†å“"
                            if original_data and 'rawData' in original_data:
                                try:
                                    raw_data = original_data['rawData']
                                    name_paths = [
                                        ['store', 'initDataObj', 'goods', 'goodsName'],
                                        ['store', 'initDataObj', 'goods', 'goods_name'],
                                        ['goods', 'goodsName'],
                                        ['goods', 'goods_name'],
                                        ['store', 'initDataObj', 'goods', 'title']
                                    ]
                                    
                                    for path in name_paths:
                                        try:
                                            value = raw_data
                                            for key in path:
                                                value = value[key]
                                            if value:
                                                goods_name = str(value)
                                                break
                                        except (KeyError, TypeError):
                                            continue
                                except:
                                    pass
                            
                            # ç®€åŒ–æ—¥å¿—ï¼šåªæ˜¾ç¤ºIDã€å•†å“åç§°å’Œä¿å­˜ä½ç½®
                            success_msg = f"âœ… IDï¼š{goods_id}ï¼ˆ{goods_name}ï¼‰å·²ä¿å­˜åˆ°\\detailsç›®å½•"
                            
                            # é˜²é‡å¤æ—¥å¿—
                            if not hasattr(self, '_last_logged_goods'):
                                self._last_logged_goods = set()
                            
                            log_key = f"{goods_id}_{goods_name}"
                            if log_key not in self._last_logged_goods:
                                print(success_msg)
                                
                                # å¦‚æœæœ‰UIæ—¥å¿—å›è°ƒï¼Œå‘é€åˆ°UI
                                if hasattr(self, 'ui_log_callback') and self.ui_log_callback:
                                    try:
                                        self.ui_log_callback(success_msg)
                                    except:
                                        pass
                                
                                # è®°å½•å·²è¾“å‡ºçš„æ—¥å¿—ï¼Œé¿å…é‡å¤
                                self._last_logged_goods.add(log_key)
                                
                                # é™åˆ¶æ—¥å¿—è®°å½•æ•°é‡ï¼Œé¿å…å†…å­˜æ³„æ¼
                                if len(self._last_logged_goods) > 1000:
                                    self._last_logged_goods.clear()
                        else:
                            print(f"âŒ æœåŠ¡å™¨ä¸‹è½½å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                            return False
                    else:
                        print(f"âŒ æœåŠ¡å™¨å“åº”é”™è¯¯: HTTP {response.status}")
                        return False

            # ä»åŸå§‹æ•°æ®æå–å­—æ®µå¹¶ä¿å­˜åˆ°CSVè¡¨æ ¼ï¼ˆåªä¿å­˜å¤„ç†åçš„å­—æ®µï¼Œä¸ä¿å­˜åŸå§‹æ•°æ®ï¼‰
            try:
                if original_data:  # ç”¨åŸå§‹æ•°æ®æå–å­—æ®µ
                    csv_data = self._extract_csv_fields(original_data)  # æå–å­—æ®µï¼šå•†å“IDã€å•†å“åç§°ã€ä»·æ ¼ç­‰
                    if csv_data and csv_data.get('å•†å“ID'):
                        self._save_to_csv(csv_data)  # åªä¿å­˜æå–çš„å­—æ®µæ•°æ®åˆ°CSVè¡¨æ ¼
            except Exception as e:
                print(f"âš ï¸ CSVä¿å­˜å¤±è´¥: {e}")

            return True

        except asyncio.TimeoutError:
            print(f"âŒ ä¸‹è½½è¶…æ—¶: {goods_id}")
            return False
        except Exception as e:
            print(f"âŒ ä»æœåŠ¡å™¨ä¸‹è½½å¤±è´¥: {e}")
            return False

    # ==================== ğŸ”¥ æ–°å¢ï¼šCSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½ ====================
    
    def _init_csv_functionality(self):
        """åˆå§‹åŒ–CSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½"""
        try:
            # è¿è¡Œæ—¶ç»Ÿè®¡åˆå§‹åŒ–
            self.runtime_parsed_count = 0
            
            # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®browser_idç¡®å®šæ­£ç¡®çš„è¾“å‡ºç›®å½•
            if self.browser_id:
                # å¦‚æœæœ‰browser_idï¼Œä¼˜å…ˆä½¿ç”¨å¯¹åº”çš„æµè§ˆå™¨ç›®å½•
                project_root = Path(__file__).parent.parent
                browser_dir = project_root / "generated_scripts" / f"browser_{self.browser_id}"
                if browser_dir.exists():
                    self.csv_output_dir = browser_dir / "output"
                else:
                    # å¦‚æœæµè§ˆå™¨ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨ä¸»ç›®å½•
                    self.csv_output_dir = project_root / "output"
            else:
                # æ²¡æœ‰browser_idæ—¶ï¼Œä½¿ç”¨å½“å‰ç›®å½•
                # ğŸ”¥ æ–°ç‰ˆè·¯å¾„ï¼šä¿å­˜åˆ°ä¸»ç›®å½•çš„outputå’Œcacheæ–‡ä»¶å¤¹
                current_file_dir = os.path.dirname(os.path.abspath(__file__))
                project_root = current_file_dir
                
                # å‘ä¸ŠæŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å«generated_scriptsçš„ç›®å½•ï¼‰
                while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                    parent = os.path.dirname(project_root)
                    if parent == project_root:  # å·²ç»åˆ°è¾¾æ ¹ç›®å½•
                        break
                    project_root = parent
                
                # åˆ›å»ºä¸»ç›®å½•çš„outputå’Œcacheæ–‡ä»¶å¤¹
                main_output_dir = Path(project_root) / "output"
                main_cache_dir = Path(project_root) / "cache"
                main_output_dir.mkdir(exist_ok=True)
                main_cache_dir.mkdir(exist_ok=True)
            
            # CSVæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åˆ°ä¸»ç›®å½•outputæ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶ååŠ ä¸Šbrowser_idåç¼€ï¼‰
            browser_id = getattr(self, 'browser_id', 'manual')  # æ‰‹åŠ¨æŠ“å–ä½¿ç”¨é»˜è®¤æ ‡è¯†
            self.csv_file_path = main_output_dir / f"æ‰‹åŠ¨æŠ“å–_å•†å“æ•°æ®_{browser_id}.csv"
            
            # ç»Ÿè®¡JSONæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åˆ°ä¸»ç›®å½•cacheæ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶ååŠ ä¸Šbrowser_idåç¼€ï¼‰
            self.stats_file_path = main_cache_dir / f"ç»Ÿè®¡æ•°é‡_{browser_id}.json"
            
            # åˆ›å»ºCSVæ–‡ä»¶å¤´ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰
            self._create_csv_header()
            
            # åˆå§‹åŒ–ç»Ÿè®¡JSONæ–‡ä»¶
            self._init_stats_file()
            
            print(f"[CSV] CSVåŠŸèƒ½å·²åˆå§‹åŒ–")
            print(f"[CSV] è¾“å‡ºç›®å½•: {self.csv_output_dir}")
            print(f"[CSV] CSVæ–‡ä»¶: {self.csv_file_path}")
            print(f"[CSV] ç»Ÿè®¡æ–‡ä»¶: {self.stats_file_path}")
            
        except Exception as e:
            print(f"âŒ CSVåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _create_csv_header(self):
        """åˆ›å»ºCSVæ–‡ä»¶å¤´ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰"""
        try:
            if not self.csv_file_path.exists():
                headers = [
                    "å•†å“ID", "å•†å“åç§°", "åº—é“ºåç§°", "å•†å“é“¾æ¥", "å½“å‰ä»·æ ¼", "åˆ¸åä»·", "å•†å“é”€é‡", "åº—é“ºé”€é‡", 
                    "é«˜æ¸…å›¾ç‰‡", "å•†å®¶ID", "å‘è´§æ—¶é—´", "å‘è´§åœ°", "å•†å“ç±»ç›®", "è¯„ä»·æ•°é‡", "æ­£åœ¨æ‹¼", "åº—é“ºå•†å“æ•°é‡", "24å°æ—¶å‘è´§", "æ–°å“", "éƒ¨åˆ†é¢„å”®", "ä¸Šæ¶æ—¶é—´", "é‡‡é›†æ—¶é—´"
                ]
                
                import csv
                with open(self.csv_file_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    writer.writerow(headers)
                print(f"[CSV] CSVæ–‡ä»¶å¤´å·²åˆ›å»º")
        except Exception as e:
            print(f"âŒ åˆ›å»ºCSVæ–‡ä»¶å¤´å¤±è´¥: {e}")
    
    def _init_stats_file(self):
        """åˆå§‹åŒ–ç»Ÿè®¡JSONæ–‡ä»¶"""
        try:
            stats_data = {
                "è§£ææ•°é‡": self.runtime_parsed_count,
                "æœ€åæ›´æ–°": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            with open(self.stats_file_path, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
            
            print(f"[CSV] ç»Ÿè®¡æ–‡ä»¶å·²åˆå§‹åŒ–: {self.runtime_parsed_count}ä¸ª")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")
    
    def _extract_csv_fields(self, raw_data: Dict) -> Optional[Dict]:
        """ä»rawDataæå–CSVéœ€è¦çš„å­—æ®µ"""
        try:
            if not raw_data or 'rawData' not in raw_data:
                return None
            
            data = raw_data['rawData']
            
            # ä»rawDataä¸­æå–goodså¯¹è±¡ï¼ˆä¸jiex.pyä¿æŒä¸€è‡´ï¼‰
            goods = data.get('store', {}).get('initDataObj', {}).get('goods', {})
            
            # æå–å›¾æ ‡ä¿¡æ¯
            icon_info = self._extract_icon_info(data)
            
            # æå–ä¸Šæ¶æ—¶é—´
            upload_time = self._extract_upload_time(data)
            
            # æŒ‰ç…§è¦æ±‚çš„å­—æ®µç»“æ„æ„å»ºCSVæ•°æ®
            csv_data = {
                'å•†å“ID': str(self._flexible_get(data, ['goodsID', 'goods_id', 'id'], '') or ''),
                'å•†å“åç§°': self._flexible_get(data, ['goodsName', 'goods_name', 'title'], '') or '',
                'å•†å“é“¾æ¥': raw_data.get('url', '') or '',
                'å½“å‰ä»·æ ¼': self._safe_price_convert(self._flexible_get(data, ['minOnSaleGroupPrice', 'price', 'min_price', 'current_price'], 0)),
                'åˆ¸åä»·': self._safe_price_convert(self._flexible_get(data, ['minOnSaleGroupPrice', 'coupon_price', 'price'], 0)),
                'å•†å“é”€é‡': self._extract_goods_sales(data) or 0,
                'åº—é“ºé”€é‡': self._extract_store_sales(data) or '',
                'é«˜æ¸…å›¾ç‰‡': self._flexible_get(data, ['hdThumbUrl', 'thumbUrl', 'image_url', 'thumb_url'], '') or '',
                'å•†å®¶ID': str(self._flexible_get(data, ['mallID', 'mall_id', 'merchant_id'], '') or ''),
                'å‘è´§æ—¶é—´': self._extract_delivery_time(data) or '',
                'å‘è´§åœ°': self._extract_delivery_location(data) or '',
                'å•†å“ç±»ç›®': self._extract_category_info(data) or '',
                'è¯„ä»·æ•°é‡': self._extract_review_count(data) or 0,
                'æ­£åœ¨æ‹¼': self._extract_grouping_info(data) or '',
                'åº—é“ºæ•°é‡': self._extract_store_count(data) or '',
                '24å°æ—¶å‘è´§': icon_info.get('has_24h_shipping', 'å¦'),
                'æ–°å“': icon_info.get('has_new_product', 'å¦'),
                'ä¸Šæ¶æ—¶é—´': upload_time or '',
                'é‡‡é›†æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return csv_data
            
        except Exception as e:
            print(f"âŒ æå–CSVå­—æ®µå¤±è´¥: {e}")
            return None
    
    def _extract_field_by_paths(self, data: Dict, paths: List[List[str]], default_value):
        """æ ¹æ®å¤šä¸ªè·¯å¾„æå–å­—æ®µå€¼"""
        for path in paths:
            try:
                value = data
                for key in path:
                    value = value[key]
                if value is not None:
                    return value
            except (KeyError, TypeError):
                continue
        return default_value
    
    def _format_category_chain(self, data: Dict) -> str:
        """æ ¼å¼åŒ–å•†å“åˆ†ç±»é“¾ï¼šä¸€çº§-äºŒçº§-ä¸‰çº§-å››çº§"""
        try:
            categories = []
            
            # åˆ†ç±»è·¯å¾„æ˜ å°„
            category_paths = [
                (['store', 'initDataObj', 'goods', 'catId1'], ['store', 'initDataObj', 'goods', 'catName1']),
                (['store', 'initDataObj', 'goods', 'catId2'], ['store', 'initDataObj', 'goods', 'catName2']),
                (['store', 'initDataObj', 'goods', 'catId3'], ['store', 'initDataObj', 'goods', 'catName3']),
                (['store', 'initDataObj', 'goods', 'catId4'], ['store', 'initDataObj', 'goods', 'catName4'])
            ]
            
            for id_path, name_path in category_paths:
                cat_id = self._extract_field_by_paths(data, [id_path], None)
                cat_name = self._extract_field_by_paths(data, [name_path], None)
                
                if cat_id and cat_name and str(cat_id) != '0':
                    categories.append(str(cat_name))
            
            return '-'.join(categories) if categories else ''
            
        except Exception as e:
            print(f"âŒ æ ¼å¼åŒ–åˆ†ç±»é“¾å¤±è´¥: {e}")
            return ''
    
    def _save_to_csv(self, csv_data: Dict) -> bool:
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶ï¼ˆå¢é‡è¿½åŠ ï¼‰"""
        try:
            import csv
            
            # æŒ‰ç…§CSVå¤´çš„é¡ºåºå‡†å¤‡æ•°æ®
            headers = [
                "å•†å“ID", "å•†å“åç§°", "å•†å“é“¾æ¥", "å½“å‰ä»·æ ¼", "åˆ¸åä»·", "å•†å“é”€é‡", "åº—é“ºé”€é‡", 
                "é«˜æ¸…å›¾ç‰‡", "å•†å®¶ID", "å‘è´§æ—¶é—´", "å‘è´§åœ°", "å•†å“ç±»ç›®", "è¯„ä»·æ•°é‡", "æ­£åœ¨æ‹¼", "åº—é“ºæ•°é‡", "24å°æ—¶å‘è´§", "æ–°å“", "ä¸Šæ¶æ—¶é—´", "é‡‡é›†æ—¶é—´"
            ]
            
            row_data = [csv_data.get(header, '') for header in headers]
            
            # è¿½åŠ åˆ°CSVæ–‡ä»¶
            with open(self.csv_file_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
            
            # æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡
            self.runtime_parsed_count += 1
            self._update_runtime_stats()
            
            # ğŸ”¥ æ·»åŠ è¯¦ç»†çš„ä¿å­˜æ—¥å¿—
            goods_id = csv_data.get('å•†å“ID', 'æœªçŸ¥')
            goods_name = csv_data.get('å•†å“åç§°', 'æœªçŸ¥å•†å“')[:30]  # åªæ˜¾ç¤ºå‰30ä¸ªå­—ç¬¦
            print(f"[CSV] âœ… å·²ä¿å­˜åˆ°è¡¨æ ¼: {goods_id} - {goods_name}...")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVæ•°æ®å¤±è´¥: {e}")
            return False
    
    def _update_runtime_stats(self):
        """æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡"""
        try:
            stats_data = {
                "è§£ææ•°é‡": self.runtime_parsed_count,
                "æœ€åæ›´æ–°": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            with open(self.stats_file_path, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
            
            print(f"[ç»Ÿè®¡] å·²è§£æ {self.runtime_parsed_count} ä¸ªå•†å“")
            
        except Exception as e:
            print(f"âŒ æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡å¤±è´¥: {e}")

    def _extract_icon_info(self, data: Dict) -> Dict:
        """æå–å›¾æ ‡ç›¸å…³ä¿¡æ¯"""
        try:
            icon_info = {
                'has_24h_shipping': 'å¦',
                'has_new_product': 'å¦'
            }
            
            # ä»å•†å“å±æ€§ä¸­æå–å›¾æ ‡ä¿¡æ¯
            goods_property = data.get('store', {}).get('initDataObj', {}).get('goods', {}).get('goodsProperty', [])
            
            for prop in goods_property:
                if prop.get('key') == '24å°æ—¶å‘è´§':
                    icon_info['has_24h_shipping'] = 'æ˜¯'
                elif prop.get('key') == 'æ–°å“':
                    icon_info['has_new_product'] = 'æ˜¯'
            
            return icon_info
        except Exception:
            return {
                'has_24h_shipping': 'å¦',
                'has_new_product': 'å¦'
            }

    def _extract_upload_time(self, data: Dict) -> str:
        """æå–ä¸Šæ¶æ—¶é—´"""
        try:
            # ä»é«˜æ¸…å›¾ç‰‡URLä¸­æå–æ—¶é—´
            goods = data.get('store', {}).get('initDataObj', {}).get('goods', {})
            hd_thumb_url = goods.get('hdThumbUrl', '')
            thumb_url = goods.get('thumbUrl', '')
            
            # ä¼˜å…ˆä½¿ç”¨é«˜æ¸…å›¾ç‰‡URLï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ™®é€šå›¾ç‰‡URL
            url = hd_thumb_url if hd_thumb_url else thumb_url
            
            if url:
                import re
                # ä»URLä¸­æå–æ—¥æœŸï¼Œæ ¼å¼å¦‚ï¼š2025-07-12
                match = re.search(r'/(\d{4}-\d{2}-\d{2})/', url)
                if match:
                    return match.group(1)
            
            return ''
        except Exception:
            return ''

    def _extract_delivery_time(self, data: Dict) -> str:
        """æå–å‘è´§æ—¶é—´ï¼ˆdeliveryTimeå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å‘è´§æ—¶é—´
            delivery_time_paths = [
                ['store', 'initDataObj', 'shipping', 'deliveryTime'],
                ['store', 'initDataObj', 'ui', 'deliveryTimeV2Section', 'mainText'],
                ['shipping', 'deliveryTime'],
                ['deliveryTime']
            ]
            
            for path in delivery_time_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_delivery_location(self, data: Dict) -> str:
        """æå–å‘è´§åœ°ï¼ˆshippingLocationå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å‘è´§åœ°
            location_paths = [
                ['store', 'initDataObj', 'shipping', 'originPlace'],
                ['store', 'initDataObj', 'shipping', 'shippingLocation'],
                ['shipping', 'originPlace'],
                ['shipping', 'shippingLocation'],
                ['shippingLocation'],
                ['originPlace']
            ]
            
            for path in location_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»UIæ–‡æœ¬ä¸­æå–å‘è´§åœ°
            try:
                delivery_section = data.get('store', {}).get('initDataObj', {}).get('ui', {}).get('deliveryTimeV2Section', {})
                sub_text = delivery_section.get('subText', '')
                if 'å‘è´§' in sub_text:
                    import re
                    match = re.search(r'(.+?)å‘è´§', sub_text)
                    if match:
                        return match.group(1)
            except:
                pass
                    
            return ''
        except Exception:
            return ''

    def _extract_category_info(self, data: Dict) -> str:
        """æå–å•†å“ç±»ç›®ï¼ˆcat1Name,cat2Name,cat3Name,cat4Nameï¼‰æŒ‰é¡ºåºç»„åˆ"""
        try:
            cat_names = []
            
            # æŒ‰é¡ºåºæå–cat1Nameåˆ°cat4Name
            for i in range(1, 5):
                cat_name_paths = [
                    ['store', 'initDataObj', 'goods', f'cat{i}Name'],
                    ['goods', f'cat{i}Name'],
                    [f'cat{i}Name']
                ]
                
                for path in cat_name_paths:
                    try:
                        value = data
                        for key in path:
                            value = value[key]
                        if value is not None and value != '':
                            cat_names.append(str(value))
                            break
                    except (KeyError, TypeError):
                        continue
            
            # æŒ‰ç…§é¡ºåºè¿æ¥ï¼Œæ²¡æœ‰çš„åˆ†ç±»ä¸æ˜¾ç¤º
            return '-'.join(cat_names) if cat_names else ''
        except Exception:
            return ''

    def _extract_review_count(self, data: Dict) -> int:
        """æå–è¯„ä»·æ•°é‡ï¼ˆreviewNumå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–è¯„ä»·æ•°é‡
            review_paths = [
                ['store', 'initDataObj', 'review', 'reviewNum'],
                ['review', 'reviewNum'],
                ['reviewNum']
            ]
            
            for path in review_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return int(value) if value else 0
                except (KeyError, TypeError, ValueError):
                    continue
                    
            return 0
        except Exception:
            return 0

    def _get_goods_object(self, data: Dict) -> Dict:
        """è·å–goodså¯¹è±¡ï¼ˆå¿½ç•¥å¤§å°å†™å’Œ_ç¬¦å·ï¼‰"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            paths = [
                ['store', 'initDataObj', 'goods'],
                ['store', 'initdataobj', 'goods'],
                ['store', 'init_data_obj', 'goods'],
                ['store', 'initDataObj', 'Goods'],
                ['store', 'initdataobj', 'Goods']
            ]
            
            for path in paths:
                try:
                    result = data
                    for key in path:
                        result = result[key]
                    if result:
                        return result
                except (KeyError, TypeError):
                    continue
            
            return {}
        except Exception:
            return {}

    def _get_field_value(self, obj: Dict, field_names: List[str], default_value):
        """è·å–å­—æ®µå€¼ï¼ˆå¿½ç•¥å¤§å°å†™å’Œ_ç¬¦å·ï¼‰"""
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥åŒ¹é…
            for field_name in field_names:
                if field_name in obj:
                    return obj[field_name]
            
            # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•å¿½ç•¥å¤§å°å†™å’Œ_ç¬¦å·çš„åŒ¹é…
            obj_keys = list(obj.keys())
            for field_name in field_names:
                # æ ‡å‡†åŒ–å­—æ®µåï¼ˆç§»é™¤_ç¬¦å·ï¼Œè½¬å°å†™ï¼‰
                normalized_field = field_name.replace('_', '').lower()
                
                for obj_key in obj_keys:
                    normalized_obj_key = obj_key.replace('_', '').lower()
                    if normalized_field == normalized_obj_key:
                        return obj[obj_key]
            
            return default_value
        except Exception:
            return default_value

    def _get_price_value(self, goods: Dict, field_names: List[str]) -> float:
        """è·å–ä»·æ ¼å€¼ï¼ˆå¤„ç†åˆ†è½¬å…ƒï¼‰"""
        try:
            price_raw = self._get_field_value(goods, field_names, 0)
            
            # å¦‚æœprice_rawæ˜¯Noneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œè¿”å›0
            if price_raw is None or price_raw == '':
                return 0.0
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(price_raw, str):
                # ç§»é™¤å¯èƒ½çš„è´§å¸ç¬¦å·å’Œç©ºæ ¼
                price_raw = price_raw.replace('Â¥', '').replace('ï¿¥', '').replace('$', '').strip()
                if not price_raw:
                    return 0.0
                try:
                    price_raw = float(price_raw)
                except ValueError:
                    return 0.0
            
            # å¦‚æœæ˜¯æ•°å­—ï¼Œè¿›è¡Œåˆ†è½¬å…ƒå¤„ç†
            if isinstance(price_raw, (int, float)):
                if price_raw > 100:  # å‡è®¾å¤§äº100çš„æ˜¯åˆ†
                    return float(price_raw) / 100
                else:
                    return float(price_raw)
            
            return 0.0
        except Exception:
            return 0.0

    def _safe_int_convert(self, value) -> int:
        """å®‰å…¨çš„æ•´æ•°è½¬æ¢"""
        try:
            if value is None:
                return 0
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(value, str):
                # ç§»é™¤å¯èƒ½çš„éæ•°å­—å­—ç¬¦
                import re
                value = re.sub(r'[^\d]', '', value)
                if not value:
                    return 0
                return int(value)
            
            # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥è½¬æ¢
            if isinstance(value, (int, float)):
                return int(value)
            
            return 0
        except Exception:
            return 0

    def _get_image_url(self, goods: Dict) -> str:
        """è·å–å›¾ç‰‡URLï¼ˆä¼˜å…ˆé«˜æ¸…å›¾ç‰‡ï¼‰"""
        try:
            hd_url = self._get_field_value(goods, ['hdThumbUrl', 'hd_thumb_url', 'hdThumbUrl'], '')
            if hd_url:
                return hd_url
            
            thumb_url = self._get_field_value(goods, ['thumbUrl', 'thumb_url', 'thumbUrl'], '')
            return thumb_url
        except Exception:
            return ''

    def _extract_goods_sales(self, data: Dict) -> int:
        """æå–å•†å“é”€é‡ï¼ˆsideSalesTipï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å•†å“é”€é‡
            sales_paths = [
                ['store', 'initDataObj', 'goods', 'sideSalesTip'],
                ['store', 'initDataObj', 'goods', 'soldQuantity'],
                ['store', 'initDataObj', 'goods', 'sales'],
                ['goods', 'sideSalesTip'],
                ['goods', 'soldQuantity'],
                ['goods', 'sales'],
                ['sideSalesTip'],
                ['soldQuantity']
            ]
            
            for path in sales_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return self._safe_int_convert(value)
                except (KeyError, TypeError):
                    continue
                    
            return 0
        except Exception:
            return 0

    def _extract_store_sales(self, data: Dict) -> str:
        """æå–åº—é“ºé”€é‡ï¼ˆsalesTipï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºé”€é‡æç¤º
            sales_tip_paths = [
                ['store', 'initDataObj', 'goods', 'salesTip'],
                ['store', 'initDataObj', 'goods', 'sales_tip'],
                ['goods', 'salesTip'],
                ['goods', 'sales_tip'],
                ['salesTip'],
                ['sales_tip']
            ]
            
            for path in sales_tip_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_grouping_info(self, data: Dict) -> str:
        """æå–æ­£åœ¨æ‹¼æ•°é‡ï¼ˆgroupsTotalå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–æ­£åœ¨æ‹¼æ•°é‡
            grouping_paths = [
                ['store', 'initDataObj', 'groupingInfo', 'groupsTotal'],
                ['store', 'initDataObj', 'groupingInfo', 'groupingNum'],
                ['groupingInfo', 'groupsTotal'],
                ['groupingInfo', 'groupingNum'],
                ['groupsTotal'],
                ['groupingNum']
            ]
            
            for path in grouping_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_store_count(self, data: Dict) -> str:
        """æå–åº—é“ºæ•°é‡ï¼ˆgoodsNumDescï¼Œå»æ‰'å•†å“æ•°é‡ï¼š'åªç•™æ•°å­—ï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºå•†å“æ•°é‡æè¿°
            store_count_paths = [
                ['store', 'initDataObj', 'goods', 'goodsNumDesc'],
                ['store', 'initDataObj', 'mall', 'goodsNumDesc'],
                ['goods', 'goodsNumDesc'],
                ['goodsNumDesc']
            ]
            
            for path in store_count_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        raw_value = str(value)
                        # å»æ‰"å•†å“æ•°é‡ï¼š"å‰ç¼€ï¼Œåªä¿ç•™æ•°å­—
                        import re
                        # æå–æ•°å­—éƒ¨åˆ†
                        numbers = re.findall(r'\d+', raw_value)
                        if numbers:
                            return numbers[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ•°å­—
                        return raw_value  # å¦‚æœæ²¡æœ‰æ•°å­—ï¼Œè¿”å›åŸå§‹å€¼
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_mall_name(self, data: Dict) -> str:
        """æå–åº—é“ºåç§°ï¼ˆmallNameå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºåç§°
            mall_name_paths = [
                ['store', 'initDataObj', 'goods', 'mallName'],
                ['store', 'initDataObj', 'mall', 'mallName'],
                ['goods', 'mallName'],
                ['mall', 'mallName'],
                ['mallName']
            ]
            
            for path in mall_name_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_presale_info(self, data: Dict) -> str:
        """æå–éƒ¨åˆ†é¢„å”®ä¿¡æ¯ï¼ˆclick_noticeå­—æ®µï¼‰ï¼Œåªè¦å­—æ®µå­˜åœ¨å°±è·³è¿‡ä¿å­˜"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–é¢„å”®ä¿¡æ¯
            presale_paths = [
                ['store', 'initDataObj', 'goods', 'click_notice'],
                ['store', 'initDataObj', 'goods', 'clickNotice'],
                ['goods', 'click_notice'],
                ['goods', 'clickNotice'],
                ['click_notice'],
                ['clickNotice']
            ]
            
            for path in presale_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        # åªè¦click_noticeå­—æ®µå­˜åœ¨ä¸”æœ‰å†…å®¹ï¼Œå°±è¿”å›è¯¥å†…å®¹ï¼ˆåç»­ä¼šè·³è¿‡ä¿å­˜ï¼‰
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''  # å­—æ®µä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆæ­£å¸¸ä¿å­˜ï¼‰
        except Exception:
            return ''

    def _safe_price_convert(self, value) -> float:
        """å®‰å…¨çš„ä»·æ ¼è½¬æ¢ï¼ˆå¤„ç†åˆ†è½¬å…ƒï¼‰"""
        try:
            if value is None or value == '':
                return 0.0
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(value, str):
                # ç§»é™¤å¯èƒ½çš„è´§å¸ç¬¦å·å’Œç©ºæ ¼
                value = value.replace('Â¥', '').replace('ï¿¥', '').replace('$', '').strip()
                if not value:
                    return 0.0
                try:
                    value = float(value)
                except ValueError:
                    return 0.0
            
            # å¦‚æœæ˜¯æ•°å­—ï¼Œè¿›è¡Œåˆ†è½¬å…ƒå¤„ç†
            if isinstance(value, (int, float)):
                if value > 100:  # å‡è®¾å¤§äº100çš„æ˜¯åˆ†
                    return float(value) / 100
                else:
                    return float(value)
            
            return 0.0
        except Exception:
            return 0.0

    def _flexible_get(self, data: Dict, keys: List[str], default):
        """çµæ´»è·å–å­—æ®µå€¼ï¼ˆæ”¯æŒå¤šä¸ªå¯èƒ½çš„é”®åï¼‰"""
        for key in keys:
            if isinstance(data, dict) and key in data:
                return data[key]
        return default

    def stop_monitoring(self):
        """åœæ­¢æŒç»­ç›‘æ§"""
        try:
            print(f"[æŒç»­ç›‘æ§] æ­£åœ¨åœæ­¢æŒç»­ç›‘æ§...")
            self.is_monitoring = False
            
            if self.monitor_thread and self.monitor_thread.is_alive():
                print(f"[æŒç»­ç›‘æ§] ç­‰å¾…ç›‘æ§çº¿ç¨‹é€€å‡º...")
                self.monitor_thread.join(timeout=10)
                
                if self.monitor_thread.is_alive():
                    print(f"[æŒç»­ç›‘æ§] âš ï¸ ç›‘æ§çº¿ç¨‹æœªèƒ½åœ¨10ç§’å†…é€€å‡º")
                else:
                    print(f"[æŒç»­ç›‘æ§] âœ… ç›‘æ§çº¿ç¨‹å·²å®‰å…¨é€€å‡º")
            
        except Exception as e:
            print(f"[æŒç»­ç›‘æ§] âŒ åœæ­¢ç›‘æ§æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        finally:
            print(f"[æŒç»­ç›‘æ§] ç›‘æ§å·²åœæ­¢")

    async def extract_current_page_ui(self) -> bool:
        """UIé›†æˆå…¥å£ç‚¹ï¼šæŠ“å–å½“å‰é¡µé¢æ•°æ®å¹¶ä¿å­˜åˆ°CSV"""
        try:
            print(f"[UI] å¼€å§‹æŠ“å–å½“å‰é¡µé¢æ•°æ®...")
            
            # è¿æ¥åˆ°æµè§ˆå™¨
            from playwright.async_api import async_playwright
            from config_manager import ConfigManager
            
            config_mgr = ConfigManager()
            debug_port = config_mgr.get_debug_port()
            
            async with async_playwright() as playwright:
                browser = await playwright.chromium.connect_over_cdp(f"http://localhost:{debug_port}")
                
                if browser.contexts:
                    context = browser.contexts[0]
                    if context.pages:
                        page = context.pages[0]
                        
                        print(f"[UI] æˆåŠŸè¿æ¥åˆ°æµè§ˆå™¨ï¼Œå¼€å§‹æŠ“å–æ•°æ®...")
                        
                        # ä½¿ç”¨ç°æœ‰çš„manual_extract_dataæ–¹æ³•
                        success = await self.manual_extract_data(page)
                        
                        if success:
                            print(f"[UI] âœ… æ•°æ®æŠ“å–æˆåŠŸ")
                            return True
                        else:
                            print(f"[UI] âŒ æ•°æ®æŠ“å–å¤±è´¥")
                            return False
                    else:
                        print(f"[UI] âŒ æ²¡æœ‰å¯ç”¨çš„é¡µé¢")
                        return False
                else:
                    print(f"[UI] âŒ æ²¡æœ‰å¯ç”¨çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡")
                    return False
                    
        except Exception as e:
            print(f"[UI] âŒ æŠ“å–å½“å‰é¡µé¢æ•°æ®å¤±è´¥: {e}")
            return False

# å…¨å±€å®ä¾‹ç®¡ç†
_manual_extractors: Dict[str, ManualDataExtractor] = {}

# è¿›ç¨‹çŠ¶æ€ç®¡ç†
_process_status_file = "manual_extraction_status.json"

def get_manual_extractor(browser_id: str, ui_log_callback=None) -> ManualDataExtractor:
    """è·å–æŒ‡å®šæµè§ˆå™¨çš„æ‰‹åŠ¨æŠ“å–å™¨å®ä¾‹"""
    if browser_id not in _manual_extractors:
        _manual_extractors[browser_id] = ManualDataExtractor(browser_id, ui_log_callback)
    return _manual_extractors[browser_id]

async def extract_current_page_ui(browser_id: str) -> bool:
    """UIé›†æˆå…¥å£ç‚¹ï¼šæŠ“å–æŒ‡å®šæµè§ˆå™¨çš„å½“å‰é¡µé¢"""
    extractor = get_manual_extractor(browser_id)
    return await extractor.extract_current_page_ui()

def start_manual_mode(browser_id: str, ui_log_callback=None):
    """å¯åŠ¨æŒ‡å®šæµè§ˆå™¨çš„æ‰‹åŠ¨æŠ“å–æ¨¡å¼"""
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›ç¨‹åœ¨è¿è¡Œ
    if _is_process_already_running(browser_id):
        print(f"âš ï¸ æµè§ˆå™¨ {browser_id} å·²æœ‰æ‰‹åŠ¨æŠ“å–è¿›ç¨‹åœ¨è¿è¡Œ")
        # ğŸ”¥ ä¿®å¤ï¼šå³ä½¿æ£€æµ‹åˆ°å·²æœ‰è¿›ç¨‹ï¼Œä¹Ÿå°è¯•é‡æ–°å¯åŠ¨
        print(f"ğŸ”„ å°è¯•é‡æ–°å¯åŠ¨æµè§ˆå™¨ {browser_id} çš„æ‰‹åŠ¨æŠ“å–è¿›ç¨‹...")
        
        # å…ˆåœæ­¢ç°æœ‰è¿›ç¨‹
        try:
            if browser_id in _manual_extractors:
                _manual_extractors[browser_id].stop_monitoring()
                print(f"âœ… å·²åœæ­¢æµè§ˆå™¨ {browser_id} çš„ç°æœ‰ç›‘æ§")
        except Exception as e:
            print(f"âš ï¸ åœæ­¢ç°æœ‰ç›‘æ§å¤±è´¥: {e}")
        
        # æ¸…é™¤è¿›ç¨‹çŠ¶æ€
        _clear_process_status(browser_id)
    
    # å¯åŠ¨ç›‘æ§
    extractor = get_manual_extractor(browser_id, ui_log_callback)
    extractor.start_manual_mode()
    
    # è®°å½•è¿›ç¨‹çŠ¶æ€
    _set_process_status(browser_id, True)
    print(f"âœ… æµè§ˆå™¨ {browser_id} æ‰‹åŠ¨æŠ“å–æ¨¡å¼å·²å¯åŠ¨")
    return True

def stop_manual_mode(browser_id: str):
    """åœæ­¢æŒ‡å®šæµè§ˆå™¨çš„æ‰‹åŠ¨æŠ“å–æ¨¡å¼"""
    try:
        if browser_id in _manual_extractors:
            _manual_extractors[browser_id].stop_monitoring()
            # æ¸…ç†è¿›ç¨‹çŠ¶æ€
            _clear_process_status(browser_id)
            print(f"âœ… æµè§ˆå™¨ {browser_id} æ‰‹åŠ¨æŠ“å–æ¨¡å¼å·²åœæ­¢")
        else:
            print(f"âš ï¸ æµè§ˆå™¨ {browser_id} æ²¡æœ‰è¿è¡Œä¸­çš„æŠ“å–å™¨")
    except Exception as e:
        print(f"âŒ åœæ­¢æ‰‹åŠ¨æŠ“å–æ¨¡å¼å¤±è´¥: {e}")

# è¿›ç¨‹çŠ¶æ€ç®¡ç†å‡½æ•°
def _is_process_already_running(browser_id: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›ç¨‹åœ¨è¿è¡Œ"""
    try:
        import os
        import json
        
        if os.path.exists(_process_status_file):
            with open(_process_status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
                return status_data.get(browser_id, False)
        return False
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥è¿›ç¨‹çŠ¶æ€å¤±è´¥: {e}")
        return False

def _set_process_status(browser_id: str, running: bool):
    """è®¾ç½®è¿›ç¨‹çŠ¶æ€"""
    try:
        import os
        import json
        
        status_data = {}
        if os.path.exists(_process_status_file):
            with open(_process_status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
        
        status_data[browser_id] = running
        
        with open(_process_status_file, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®è¿›ç¨‹çŠ¶æ€å¤±è´¥: {e}")

def _clear_process_status(browser_id: str):
    """æ¸…é™¤è¿›ç¨‹çŠ¶æ€"""
    try:
        import os
        import json
        
        if os.path.exists(_process_status_file):
            with open(_process_status_file, 'r', encoding='utf-8') as f:
                status_data = json.load(f)
            
            if browser_id in status_data:
                del status_data[browser_id]
                
            with open(_process_status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"âš ï¸ æ¸…é™¤è¿›ç¨‹çŠ¶æ€å¤±è´¥: {e}")

# UIé›†æˆæ¨¡å¼ - å·²ç§»é™¤å‘½ä»¤è¡Œæµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("sd.py å·²é›†æˆåˆ°UIä¸­ï¼Œè¯·é€šè¿‡UIç•Œé¢ä½¿ç”¨æ‰‹åŠ¨æŠ“å–åŠŸèƒ½")