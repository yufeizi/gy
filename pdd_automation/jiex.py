#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
jiex.py - è¯¦æƒ…é¡µæ•°æ®æŠ“å–æ¨¡å—
åŠŸèƒ½ï¼š
1. ç‚¹å‡»è¿›å…¥è¯¦æƒ…é¡µåç«‹å³æŠ“å–å®Œæ•´çš„window.rawData
2. ä»¥å•†å“IDå‘½åä¿å­˜ä¸ºå‹ç¼©JSONçš„TXTæ–‡æ¡£
3. ç»´æŠ¤å·²ç‚¹å‡»å•†å“çš„JSONæ–‡ä»¶ç”¨äºè¿‡æ»¤
4. æ”¯æŒåŠ å¯†ä¸Šä¼ åˆ°æœåŠ¡å™¨ï¼ˆé¢„ç•™æ¥å£ï¼‰
5. ğŸ”¥ æ–°å¢ï¼šå·²æœç´¢å…³é”®è¯ä¼ è¾“åˆ°ä¸»ç¨‹åºï¼ˆæ¯10åˆ†é’Ÿï¼‰
6. ğŸ”¥ æ–°å¢ï¼šUIæ—¥å¿—æ˜¾ç¤ºï¼ˆåªæ˜¾ç¤ºä¿å­˜æˆåŠŸæ—¥å¿—ï¼‰
"""

import os
import json
import time
import asyncio
import threading
from datetime import datetime
from typing import Dict, List, Set, Optional
from pathlib import Path

# ğŸ”¥ å¤„ç†config_managerå¯¼å…¥é—®é¢˜
try:
    from config_manager import ConfigManager
    print("config_managerå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"[è­¦å‘Š] config_managerå¯¼å…¥å¤±è´¥: {e}")
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ›¿ä»£ç±»
    class ConfigManager:
        def __init__(self, *args, **kwargs):
            self.config = {}

        def get_config(self):
            return self.config

        def get_browser_id(self):
            return "default"

# ğŸ”¥ å·²åˆ é™¤ui_communicationå¯¼å…¥ï¼Œä½¿ç”¨ç®€å•çš„æ—¥å¿—è¾“å‡º
def log_message(message: str):
    """ç®€å•çš„æ—¥å¿—è¾“å‡ºå‡½æ•°"""
    print(f"[æ—¥å¿—] {message}")

class DetailPageExtractor:
    """è¯¦æƒ…é¡µæ•°æ®æŠ“å–å™¨"""

    def __init__(self, browser_id: str = None, config_file: str = None):
        """
        åˆå§‹åŒ–è¯¦æƒ…é¡µæŠ“å–å™¨

        Args:
            browser_id: æµè§ˆå™¨IDï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        """
        
        # åŠ è½½é…ç½®ç®¡ç†å™¨
        try:
            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œå°è¯•æ‰¾åˆ°æµè§ˆå™¨ä¸“ç”¨é…ç½®
            if not config_file:
                detected_browser_id = self._detect_browser_id()
                if detected_browser_id != "default_browser_id":
                    # å°è¯•æ‰¾åˆ°æµè§ˆå™¨ä¸“ç”¨é…ç½®æ–‡ä»¶
                    current_file_dir = os.path.dirname(os.path.abspath(__file__))
                    parent_dir = os.path.dirname(current_file_dir)
                    browser_config_path = os.path.join(parent_dir, "generated_scripts", f"browser_{detected_browser_id}", f"config_{detected_browser_id}.json")
                    if os.path.exists(browser_config_path):
                        config_file = browser_config_path
                        print(f"[é…ç½®] æ‰¾åˆ°æµè§ˆå™¨ä¸“ç”¨é…ç½®: {config_file}")

            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿ä¼ å…¥æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶è·¯å¾„
            if config_file and os.path.exists(config_file):
                self.config_mgr = ConfigManager(config_file)
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶
                default_config = os.path.join(os.path.dirname(os.path.abspath(__file__)), "config_api.json")
                self.config_mgr = ConfigManager(default_config)

            self.browser_id = browser_id or self.config_mgr.get_browser_id()
            self.browser_id_short = self.config_mgr.get_browser_id_short()
        except Exception as e:
            print(f"[è­¦å‘Š] é…ç½®ç®¡ç†å™¨åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
            self.browser_id = browser_id or self._detect_browser_id()
            self.browser_id_short = self.browser_id[-6:] if self.browser_id else "unknown"

        # è®¾ç½®è¾“å‡ºç›®å½• - å½»åº•ä¿®å¤è·¯å¾„é€»è¾‘
        current_file_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ğŸ”¥ ä¿®å¤ï¼šç®€åŒ–è·¯å¾„é€»è¾‘ï¼Œé¿å…åµŒå¥—ç›®å½•
        if "browser_" in current_file_dir and self.browser_id in current_file_dir:
            # å·²ç»åœ¨æµè§ˆå™¨ç›®å½•ä¸­è¿è¡Œ
            self.output_dir = Path(current_file_dir)
            # details_diræŒ‡å‘ä¸»ç›®å½•ï¼ˆç”¨äºä»æœåŠ¡å™¨ä¸‹è½½çš„æ•°æ®ï¼‰
            project_root = current_file_dir
            while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                parent = os.path.dirname(project_root)
                if parent == project_root:
                    break
                project_root = parent
            
            # ç¡®ä¿project_rootæ˜¯ä¸»ç›®å½•
            if "generated_scripts" in str(project_root):
                project_root = os.path.dirname(project_root)
            
            # ğŸ”¥ ä¿®å¤ï¼šè®¾ç½®ä¸ºå®ä¾‹å±æ€§
            self.project_root = Path(project_root)
            self.details_dir = self.project_root / "details"
            self.logs_dir = self.output_dir / "logs"
        elif "generated_scripts" in current_file_dir:
            # ğŸ”¥ ä¿®å¤ï¼šåœ¨generated_scriptsç›®å½•ä¸­è¿è¡Œæ—¶ï¼ŒoutputæŒ‡å‘æµè§ˆå™¨ç›®å½•ï¼ŒdetailsæŒ‡å‘ä¸»ç›®å½•
            try:
                # ä»å½“å‰è·¯å¾„ä¸­æå–æµè§ˆå™¨ID
                path_parts = current_file_dir.split(os.sep)
                browser_dir_index = None
                for i, part in enumerate(path_parts):
                    if part.startswith('browser_'):
                        browser_dir_index = i
                        break
                
                if browser_dir_index is not None:
                    # æ‰¾åˆ°äº†æµè§ˆå™¨ç›®å½•ï¼Œä½¿ç”¨å®ƒä½œä¸ºoutput_dir
                    browser_dir = os.sep.join(path_parts[:browser_dir_index + 1])
                    self.output_dir = Path(browser_dir)
                    
                    # æ‰¾åˆ°ä¸»ç›®å½•ï¼ˆåŒ…å«generated_scriptsçš„ç›®å½•ï¼‰
                    project_root = current_file_dir
                    while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                        parent = os.path.dirname(project_root)
                        if parent == project_root:
                            break
                        project_root = parent
                    
                    # ç¡®ä¿project_rootæ˜¯ä¸»ç›®å½•
                    if "generated_scripts" in str(project_root):
                        project_root = os.path.dirname(project_root)
                    
                    # ğŸ”¥ ä¿®å¤ï¼šè®¾ç½®ä¸ºå®ä¾‹å±æ€§
                    self.project_root = Path(project_root)
                    # details_diræŒ‡å‘ä¸»ç›®å½•ï¼ˆç”¨äºä»æœåŠ¡å™¨ä¸‹è½½çš„æ•°æ®ï¼‰
                    self.details_dir = self.project_root / "details"
                    # logs_diræŒ‡å‘æµè§ˆå™¨ç›®å½•
                    self.logs_dir = self.output_dir / "logs"
                    
                    print(f"[è·¯å¾„ä¿®å¤] æ£€æµ‹åˆ°åœ¨generated_scriptsä¸­è¿è¡Œ:")
                    print(f"  - output_dir: {self.output_dir} (æµè§ˆå™¨ç›®å½•)")
                    print(f"  - details_dir: {self.details_dir} (ä¸»ç›®å½•)")
                else:
                    # æ²¡æ‰¾åˆ°æµè§ˆå™¨ç›®å½•ï¼Œä½¿ç”¨ä¸»ç›®å½•
                    project_root = current_file_dir
                    while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                        parent = os.path.dirname(project_root)
                        if parent == project_root:
                            break
                        project_root = parent
                    
                    self.output_dir = Path(project_root)
                    self.details_dir = self.output_dir / "details"
                    self.logs_dir = self.output_dir / "logs"
                
            except Exception as e:
                print(f"[è­¦å‘Š] è·¯å¾„æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ä¸»ç›®å½•: {e}")
                # å›é€€åˆ°ä¸»ç›®å½•
                project_root = current_file_dir
                while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                    parent = os.path.dirname(project_root)
                    if parent == project_root:
                        break
                    project_root = parent
                
                self.output_dir = Path(project_root)
                self.details_dir = self.output_dir / "details"
                self.logs_dir = self.output_dir / "logs"
        else:
            # åœ¨ä¸»ç›®å½•ä¸­è¿è¡Œï¼Œå°è¯•æ‰¾åˆ°æµè§ˆå™¨ç›®å½•
            try:
                project_root = current_file_dir
                while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                    parent = os.path.dirname(project_root)
                    if parent == project_root:
                        break
                    project_root = parent

                browser_dir = os.path.join(project_root, "generated_scripts", f"browser_{self.browser_id}")
                if os.path.exists(browser_dir):
                    # ğŸ”¥ ä¿®å¤ï¼šè®¾ç½®ä¸ºå®ä¾‹å±æ€§
                    self.project_root = Path(project_root)
                    # output_diræŒ‡å‘æµè§ˆå™¨ç›®å½•ï¼ˆç”¨äºCSVç­‰è¾“å‡ºæ–‡ä»¶ï¼‰
                    self.output_dir = Path(browser_dir)
                    # details_diræŒ‡å‘ä¸»ç›®å½•ï¼ˆç”¨äºä»æœåŠ¡å™¨ä¸‹è½½çš„æ•°æ®ï¼‰
                    self.details_dir = self.project_root / "details"
                    # logs_diræŒ‡å‘æµè§ˆå™¨ç›®å½•
                    self.logs_dir = self.output_dir / "logs"
                    
                    print(f"[è·¯å¾„è®¾ç½®] åœ¨ä¸»ç›®å½•ä¸­è¿è¡Œ:")
                    print(f"  - output_dir: {self.output_dir} (æµè§ˆå™¨ç›®å½•)")
                    print(f"  - details_dir: {self.details_dir} (ä¸»ç›®å½•)")
                else:
                    # å›é€€åˆ°å½“å‰ç›®å½•
                    self.output_dir = Path(current_file_dir)
                    self.details_dir = self.output_dir / "details"
                    self.logs_dir = self.output_dir / "logs"
            except Exception as e:
                print(f"[è­¦å‘Š] è·¯å¾„æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨å½“å‰ç›®å½•: {e}")
                self.output_dir = Path(current_file_dir)
                self.details_dir = self.output_dir / "details"
                self.logs_dir = self.output_dir / "logs"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.details_dir.mkdir(exist_ok=True)
        self.logs_dir.mkdir(exist_ok=True)

        # å·²ç‚¹å‡»å•†å“æ–‡ä»¶
        self.clicked_products_file = self.logs_dir / f"clicked_products_{self.browser_id_short}.json"

        # ä»»åŠ¡çŠ¶æ€æ–‡ä»¶
        self.task_status_file = self.logs_dir / "task_status.json"

        # åŠ è½½å·²ç‚¹å‡»å•†å“åˆ—è¡¨
        self.clicked_products = self._load_clicked_products()

        print(f"[æµè§ˆå™¨] ID: {self.browser_id_short} | å·²ç‚¹å‡»å•†å“: {len(self.clicked_products)}ä¸ª")

        # ğŸ”¥ æ–°å¢ï¼šå·²æœç´¢å…³é”®è¯ä¼ è¾“åŠŸèƒ½
        self.searched_keywords_file = self.logs_dir / f"searched_keywords_{self.browser_id_short}.json"
        self.main_keywords_file = None
        self.transfer_interval = 600  # 10åˆ†é’Ÿä¼ è¾“ä¸€æ¬¡
        self.last_transfer_time = 0
        self.transfer_thread = None
        self.is_transfer_running = False
        
        # åˆå§‹åŒ–å·²æœç´¢å…³é”®è¯æ–‡ä»¶
        self._init_searched_keywords_file()
        
        # å¯åŠ¨å…³é”®è¯ä¼ è¾“çº¿ç¨‹
        self._start_keyword_transfer_thread()

        # ğŸ”¥ æ–°å¢ï¼šCSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½åˆå§‹åŒ–
        self._init_csv_functionality()
        
        # ğŸ”¥ æ–°å¢ï¼šç®€åŒ–è­¦æŠ¥çŠ¶æ€ç®¡ç†
        self._alarm_played = False  # è­¦æŠ¥æ˜¯å¦å·²æ’­æ”¾
        self._popup_shown = False   # å¼¹çª—æ˜¯å¦å·²æ˜¾ç¤º

    def wait_for_previous_task(self):
        """ğŸ”¥ ç­‰å¾…ä¸Šä¸€ä¸ªä»»åŠ¡å®Œæˆ - æ’é˜Ÿæœºåˆ¶"""
        print("â³ æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€...")
        while True:
            try:
                if self.task_status_file.exists():
                    with open(self.task_status_file, 'r', encoding='utf-8') as f:
                        status = json.load(f)

                    # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ä»»åŠ¡åœ¨è¿è¡Œ
                    running_tasks = [task for task, running in status.items() if running]
                    if running_tasks:
                        print(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ: {', '.join(running_tasks)}")
                        time.sleep(1)
                        continue
                    else:
                        print("[æˆåŠŸ] ä»»åŠ¡é˜Ÿåˆ—ç©ºé—²ï¼Œå¯ä»¥å¼€å§‹æ‰§è¡Œ")
                        break
                else:
                    print("[æˆåŠŸ] ä»»åŠ¡çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯ä»¥å¼€å§‹æ‰§è¡Œ")
                    break
            except Exception as e:
                print(f"[è­¦å‘Š] æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¼‚å¸¸: {e}")
                break

    def set_task_status(self, task_name, running):
        """è®¾ç½®ä»»åŠ¡çŠ¶æ€"""
        try:
            status = {}
            if self.task_status_file.exists():
                with open(self.task_status_file, 'r', encoding='utf-8') as f:
                    status = json.load(f)

            status[task_name] = running
            with open(self.task_status_file, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[é”™è¯¯] è®¾ç½®ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")

    def _init_searched_keywords_file(self):
        """åˆå§‹åŒ–å·²æœç´¢å…³é”®è¯æ–‡ä»¶"""
        try:
            if not self.searched_keywords_file.exists():
                initial_data = {
                    'searched_keywords': [],
                    'last_update': datetime.now().isoformat()
                }
                with open(self.searched_keywords_file, 'w', encoding='utf-8') as f:
                    json.dump(initial_data, f, ensure_ascii=False, indent=2)
                print(f"[å…³é”®è¯] åˆå§‹åŒ–å·²æœç´¢å…³é”®è¯æ–‡ä»¶: {self.searched_keywords_file}")
        except Exception as e:
            print(f"[é”™è¯¯] åˆå§‹åŒ–å·²æœç´¢å…³é”®è¯æ–‡ä»¶å¤±è´¥: {e}")

    def _start_keyword_transfer_thread(self):
        """å¯åŠ¨å…³é”®è¯ä¼ è¾“çº¿ç¨‹"""
        try:
            if not self.is_transfer_running:
                self.is_transfer_running = True
                self.transfer_thread = threading.Thread(target=self._keyword_transfer_worker, daemon=True)
                self.transfer_thread.start()
                print(f"[å…³é”®è¯] å…³é”®è¯ä¼ è¾“çº¿ç¨‹å·²å¯åŠ¨ï¼Œä¼ è¾“é—´éš”: {self.transfer_interval}ç§’")
        except Exception as e:
            print(f"[é”™è¯¯] å¯åŠ¨å…³é”®è¯ä¼ è¾“çº¿ç¨‹å¤±è´¥: {e}")

    def _keyword_transfer_worker(self):
        """å…³é”®è¯ä¼ è¾“å·¥ä½œçº¿ç¨‹"""
        while self.is_transfer_running:
            try:
                current_time = time.time()
                if current_time - self.last_transfer_time >= self.transfer_interval:
                    self._transfer_searched_keywords()
                    self.last_transfer_time = current_time
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                print(f"[é”™è¯¯] å…³é”®è¯ä¼ è¾“å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
                time.sleep(60)

    def _transfer_searched_keywords(self):
        """ä¼ è¾“å·²æœç´¢å…³é”®è¯åˆ°ä¸»ç¨‹åº"""
        try:
            # æŸ¥æ‰¾ä¸»ç¨‹åºç›®å½•
            main_dir = self._find_main_directory()
            if not main_dir:
                print("[è­¦å‘Š] æœªæ‰¾åˆ°ä¸»ç¨‹åºç›®å½•ï¼Œè·³è¿‡å…³é”®è¯ä¼ è¾“")
                return

            main_keywords_file = main_dir / "å·²æœç´¢å…³é”®è¯.json"
            
            # è¯»å–æµè§ˆå™¨å·²æœç´¢å…³é”®è¯
            if not self.searched_keywords_file.exists():
                return

            with open(self.searched_keywords_file, 'r', encoding='utf-8') as f:
                browser_data = json.load(f)

            browser_keywords = set(browser_data.get('searched_keywords', []))

            if not browser_keywords:
                return

            # ğŸ”¥ ä½¿ç”¨æ–‡ä»¶é”é¿å…å¤šæµè§ˆå™¨å†²çª
            import time
            import random
            
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    # éšæœºå»¶è¿Ÿé¿å…ç«äº‰æ¡ä»¶
                    time.sleep(random.uniform(0.1, 0.5))
                    
                    # è¯»å–ä¸»ç¨‹åºå·²æœç´¢å…³é”®è¯
                    main_keywords = set()
                    main_data = {}
                    if main_keywords_file.exists():
                        with open(main_keywords_file, 'r', encoding='utf-8') as f:
                            main_data = json.load(f)
                        main_keywords = set(main_data.get('searched_keywords', []))

                    # åˆå¹¶å…³é”®è¯
                    combined_keywords = main_keywords.union(browser_keywords)
                    new_keywords = browser_keywords - main_keywords

                    if new_keywords:
                        # æ›´æ–°ä¸»ç¨‹åºæ–‡ä»¶
                        updated_data = {
                            'searched_keywords': sorted(list(combined_keywords)),
                            'last_update': datetime.now().isoformat(),
                            'browser_updates': {
                                **main_data.get('browser_updates', {}),
                                self.browser_id_short: {
                                    'last_update': datetime.now().isoformat(),
                                    'keywords_count': len(browser_keywords)
                                }
                            }
                        }

                        with open(main_keywords_file, 'w', encoding='utf-8') as f:
                            json.dump(updated_data, f, ensure_ascii=False, indent=2)

                        print(f"[æˆåŠŸ] å…³é”®è¯ä¼ è¾“: +{len(new_keywords)}ä¸ª")
                    else:
                        pass
                    
                    # æˆåŠŸå®Œæˆï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break
                    
                except (OSError, IOError, json.JSONDecodeError) as e:
                    print(f"[è­¦å‘Š] æ–‡ä»¶æ“ä½œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        print("[é”™è¯¯] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡æœ¬æ¬¡ä¼ è¾“")
                        return
                    time.sleep(random.uniform(1, 2))  # ç­‰å¾…åé‡è¯•

        except Exception as e:
            print(f"[é”™è¯¯] ä¼ è¾“å·²æœç´¢å…³é”®è¯å¤±è´¥: {e}")

    def _find_main_directory(self):
        """æŸ¥æ‰¾ä¸»ç¨‹åºç›®å½•"""
        try:
            current_dir = Path(__file__).parent
            while current_dir.parent != current_dir:
                if (current_dir / "generated_scripts").exists():
                    return current_dir
                current_dir = current_dir.parent
            return None
        except Exception as e:
            print(f"[é”™è¯¯] æŸ¥æ‰¾ä¸»ç¨‹åºç›®å½•å¤±è´¥: {e}")
            return None

    def add_searched_keyword(self, keyword: str):
        """æ·»åŠ å·²æœç´¢å…³é”®è¯"""
        try:
            if not self.searched_keywords_file.exists():
                self._init_searched_keywords_file()

            with open(self.searched_keywords_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            keywords = set(data.get('searched_keywords', []))
            if keyword not in keywords:
                keywords.add(keyword)
                data['searched_keywords'] = sorted(list(keywords))
                data['last_update'] = datetime.now().isoformat()

                with open(self.searched_keywords_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

                # ä¸æ˜¾ç¤ºå…·ä½“çš„å…³é”®è¯ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                # print(f"[å…³é”®è¯] æ–°å¢å·²æœç´¢å…³é”®è¯: {keyword}")
        except Exception as e:
            print(f"[é”™è¯¯] æ·»åŠ å·²æœç´¢å…³é”®è¯å¤±è´¥: {e}")

    def _detect_browser_id(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹æµè§ˆå™¨ID"""
        try:
            # ä»å½“å‰ç›®å½•è·å–æµè§ˆå™¨ID
            current_dir = os.getcwd()
            if 'browser_' in current_dir:
                browser_id = current_dir.split('browser_')[-1]
                return browser_id

            # ä»é…ç½®æ–‡ä»¶è·å–
            config_files = [f for f in os.listdir('.') if f.startswith('config_') and f.endswith('.json')]
            if config_files:
                with open(config_files[0], 'r', encoding='utf-8') as f:
                    config = json.load(f)
                browser_id = config.get('browser_info', {}).get('browser_id')
                if browser_id:
                    return browser_id

            # ğŸ”¥ æ–°å¢ï¼šä»generated_scriptsç›®å½•æ£€æµ‹æµè§ˆå™¨ID
            current_file_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(current_file_dir)
            generated_scripts_dir = os.path.join(parent_dir, "generated_scripts")

            if os.path.exists(generated_scripts_dir):
                try:
                    browser_dirs = [d for d in os.listdir(generated_scripts_dir)
                                  if d.startswith('browser_') and os.path.isdir(os.path.join(generated_scripts_dir, d))]
                    if browser_dirs:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æµè§ˆå™¨ç›®å½•
                        browser_dir = browser_dirs[0]
                        browser_id = browser_dir.replace('browser_', '')
                        print(f"[æ£€æµ‹] ä»generated_scriptsæ£€æµ‹åˆ°æµè§ˆå™¨ID: {browser_id}")
                        return browser_id
                except Exception as e:
                    print(f"[è­¦å‘Š] æ£€æµ‹æµè§ˆå™¨ç›®å½•å¤±è´¥: {e}")

            # ğŸ”¥ ä¿®å¤ç¡¬ç¼–ç ï¼šä½¿ç”¨é€šç”¨é»˜è®¤ID
            return "default_browser_id"
        except Exception as e:
            print(f"[è­¦å‘Š] æ£€æµ‹æµè§ˆå™¨IDå¤±è´¥: {e}")
            return "default_browser_id"

    def _load_clicked_products(self) -> Set[str]:
        """åŠ è½½å·²ç‚¹å‡»å•†å“åˆ—è¡¨ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            if self.clicked_products_file.exists():
                with open(self.clicked_products_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        # ğŸ”¥ å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶å·²ç‚¹å‡»å•†å“æ•°é‡ä¸ºæœ€è¿‘10000ä¸ª
                        valid_ids = []
                        for item in data[-10000:]:  # åªä¿ç•™æœ€è¿‘10000ä¸ª
                            if isinstance(item, str) and item.isdigit() and len(item) > 6:
                                valid_ids.append(item)
                        print(f"[ä¼˜åŒ–] åŠ è½½äº†{len(valid_ids)}ä¸ªæœ‰æ•ˆå•†å“IDï¼ˆé™åˆ¶æœ€å¤š10000ä¸ªï¼‰")
                        return set(valid_ids)
                    elif isinstance(data, dict):
                        clicked_products = data.get('clicked_products', [])
                        # åŒæ ·è¿‡æ»¤å’Œé™åˆ¶æ•°é‡
                        valid_ids = []
                        for item in clicked_products[-10000:]:  # åªä¿ç•™æœ€è¿‘10000ä¸ª
                            if isinstance(item, str) and item.isdigit() and len(item) > 6:
                                valid_ids.append(item)
                        return set(valid_ids)
            else:
                print(f"[ä¿¡æ¯] å·²ç‚¹å‡»å•†å“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶: {self.clicked_products_file}")
                empty_set = set()
                self._save_clicked_products_with_data(empty_set)
            return set()
        except Exception as e:
            print(f"[è­¦å‘Š] åŠ è½½å·²ç‚¹å‡»å•†å“å¤±è´¥: {e}")
            return set()

    # ğŸ”¥ å·²åˆ é™¤æœ¬åœ°ä¿å­˜æ–¹æ³• - æ•°æ®ç›´æ¥é€šè¿‡suoyin.pyåŠ å¯†ä¸Šä¼ åˆ°æœåŠ¡å™¨

    def is_product_clicked(self, product_id: str) -> bool:
        """æ£€æŸ¥å•†å“æ˜¯å¦å·²è¢«ç‚¹å‡»è¿‡"""
        return str(product_id) in self.clicked_products

    def mark_product_clicked(self, product_id: str):
        """æ ‡è®°å•†å“ä¸ºå·²ç‚¹å‡»ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰"""
        self.clicked_products.add(str(product_id))
        
        # ğŸ”¥ å†…å­˜ä¼˜åŒ–ï¼šå¦‚æœå·²ç‚¹å‡»å•†å“è¶…è¿‡10000ä¸ªï¼Œæ¸…ç†è€çš„ä¸€åŠ
        if len(self.clicked_products) > 10000:
            # ä¿ç•™æœ€è¿‘5000ä¸ªï¼ˆç”±äºsetè‡ªåŠ¨å»é‡ï¼‰
            recent_products = list(self.clicked_products)[-5000:]
            self.clicked_products = set(recent_products)
            print(f"[ä¼˜åŒ–] å·²ç‚¹å‡»å•†å“è¶…é™ï¼Œæ¸…ç†åä¿ç•™{len(self.clicked_products)}ä¸ª")
        
        self._save_clicked_products()

    def _save_clicked_products(self):
        """ä¿å­˜å·²ç‚¹å‡»å•†å“åˆ—è¡¨åˆ°æ–‡ä»¶"""
        try:
            self._save_clicked_products_with_data(self.clicked_products)
        except Exception as e:
            pass

    def _save_clicked_products_with_data(self, clicked_products_set):
        """ä¿å­˜å·²ç‚¹å‡»å•†å“æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿logsç›®å½•å­˜åœ¨
            self.logs_dir.mkdir(exist_ok=True)

            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶ä¿å­˜
            clicked_list = list(clicked_products_set)

            with open(self.clicked_products_file, 'w', encoding='utf-8') as f:
                json.dump(clicked_list, f, ensure_ascii=False, indent=2)

        except Exception as e:
            pass


    async def extract_detail_data(self, page) -> Optional[Dict]:
        """
        ä»è¯¦æƒ…é¡µæŠ“å–window.rawDataæ•°æ®
        """
        try:
            # æ£€æŸ¥ window.rawData æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸º null
            is_ready = await page.evaluate("() => typeof window.rawData !== 'undefined' && window.rawData !== null")
            
            if is_ready:
                print("âœ… æ‰¾åˆ° window.rawDataï¼Œæ­£åœ¨æå–...")
                # ç›´æ¥è¿”å›JSå¯¹è±¡ï¼ŒPlaywrightä¼šè‡ªåŠ¨å°†å…¶è½¬æ¢ä¸ºPythonå­—å…¸
                raw_data = await page.evaluate("() => window.rawData")
                
                if raw_data:
                    # æ„å»ºè¿”å›æ•°æ®ç»“æ„
                    full_data = {
                        'rawData': raw_data,
                        'url': await page.evaluate("() => window.location.href"),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    # æå–å•†å“ID
                    goods_id = self._extract_goods_id(full_data)
                    if goods_id:
                        print(f"ğŸ‰ æˆåŠŸæŠ“å–åˆ°æ•°æ®ï¼Œå•†å“ID: {goods_id}")
                        return {
                            'goods_id': goods_id,
                            'data': full_data,
                            'extract_time': datetime.now().isoformat()
                        }
                    else:
                        print("[è­¦å‘Š] æœªèƒ½æå–åˆ°å•†å“ID")
                        return None
                else:
                    print("ğŸ”´ rawDataä¸ºç©º")
                    return None
            else:
                print("â„¹ï¸ å½“å‰é¡µé¢æœªæ‰¾åˆ° window.rawDataã€‚")
                return None
                
        except Exception as e:
            print(f"âŒ åœ¨æå–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _extract_goods_id(self, raw_data: Dict) -> Optional[str]:
        """ä»rawDataä¸­æå–å•†å“ID"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            paths = [
                ['rawData', 'store', 'initDataObj', 'goods', 'goodsID'],
                ['rawData', 'store', 'initDataObj', 'goods', 'goodsId'],
                ['rawData', 'store', 'initDataObj', 'queries', 'goods_id'],
                ['rawData', 'goods', 'goodsID'],
                ['rawData', 'goods', 'goodsId']
            ]

            for path in paths:
                try:
                    value = raw_data
                    for key in path:
                        value = value[key]
                    if value:
                        return str(value)
                except (KeyError, TypeError):
                    continue

            # ä»URLä¸­æå–
            url = raw_data.get('url', '')
            if url:
                import re
                patterns = [
                    r'goods_id[=\/](\d+)',
                    r'\/g\/(\d+)',
                    r'\/goods\/(\d+)',
                    r'\/(\d{10,})'
                ]
                for pattern in patterns:
                    match = re.search(pattern, url)
                    if match:
                        return match.group(1)

            return None
        except Exception as e:
            print(f"[è­¦å‘Š] æå–å•†å“IDå¤±è´¥: {e}")
            return None

    async def process_detail_page(self, page, target_goods_id: str = None) -> bool:
        """
        å¤„ç†è¯¦æƒ…é¡µï¼šæŠ“å–æ•°æ®å¹¶ä¿å­˜

        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            target_goods_id: ç›®æ ‡å•†å“IDï¼ˆå¯é€‰ï¼Œç”¨äºéªŒè¯ï¼‰

        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        try:
            # 1. æŠ“å–æ•°æ®
            extracted_data = await self.extract_detail_data(page)
            if not extracted_data:
                print("[å¤±è´¥] æ•°æ®æŠ“å–å¤±è´¥")
                # å¯åŠ¨è­¦æŠ¥å’Œå¼¹çª—ç³»ç»Ÿ
                await self._start_alert_system()
                return False

            goods_id = extracted_data['goods_id']

            # ğŸ”¥ æ–°å¢ï¼šå¦‚æœæŒ‡å®šäº†ç›®æ ‡å•†å“IDï¼Œè¿›è¡ŒéªŒè¯
            if target_goods_id and str(goods_id) != str(target_goods_id):
                print(f"[è­¦å‘Š] å•†å“IDä¸åŒ¹é…: æœŸæœ›={target_goods_id}, å®é™…={goods_id}")
                # ç»§ç»­å¤„ç†ï¼Œä½†ä½¿ç”¨æŒ‡å®šçš„ID
                goods_id = str(target_goods_id)

            # 2. æ£€æŸ¥æ˜¯å¦å·²ç‚¹å‡»è¿‡
            if self.is_product_clicked(goods_id):
                print(f"[è·³è¿‡] å•†å“ {goods_id} å·²è¢«ç‚¹å‡»è¿‡")
                return True

            # 3. æ ‡è®°ä¸ºå·²ç‚¹å‡»
            self.mark_product_clicked(goods_id)

            # ğŸ”¥ å·²åˆ é™¤æœ¬åœ°ä¿å­˜åŠŸèƒ½ - ç°åœ¨åªä½¿ç”¨åŠ å¯†ä¸Šä¼ åˆ°æœåŠ¡å™¨çš„æ–¹å¼
            # è¯¦æƒ…é¡µæ•°æ®å¤„ç†å·²é›†æˆåˆ° product_clicker.py ä¸­
            # ä½¿ç”¨ä¸‰é‡åŠ å¯†å‹ç¼©ä¸Šä¼ åˆ°æœåŠ¡å™¨ï¼Œç„¶åä»æœåŠ¡å™¨ä¸‹è½½åˆ°æœ¬åœ°

            print(f"[æˆåŠŸ] å•†å“æ•°æ®æŠ“å–æˆåŠŸ: ID:{goods_id}")
            print(f"[INFO] æ•°æ®å¤„ç†å·²ç§»è‡³ product_clicker.py çš„é›†æˆæ¨¡å¼")
            return True

        except Exception as e:
            print(f"[é”™è¯¯] å¤„ç†è¯¦æƒ…é¡µå¤±è´¥: {e}")
            return False

    async def _start_alert_system(self):
        """ğŸ”¥ ç®€åŒ–çš„è­¦æŠ¥ç³»ç»Ÿï¼šç›´æ¥å¼¹çª—å’Œ5å£°å£°éŸ³è­¦æŠ¥ + UIæš‚åœé…åˆ"""
        try:
            print("ğŸš¨ è¯¦æƒ…é¡µæ•°æ®æŠ“å–å¤±è´¥ï¼Œå¯åŠ¨è­¦æŠ¥ç³»ç»Ÿ")
            
            # é‡ç½®è­¦æŠ¥çŠ¶æ€ï¼Œå…è®¸é‡æ–°æ’­æ”¾
            self.reset_alarm_status()
            
            # ğŸ”¥ æ–°å¢ï¼šåˆ›å»ºæš‚åœæ ‡å¿—æ–‡ä»¶ï¼Œè®©UIæ˜¾ç¤ºæš‚åœçŠ¶æ€
            await self._create_pause_flag_for_ui()
            
            # ç›´æ¥æ’­æ”¾5å£°è­¦æŠ¥
            await self._play_alarm_sound()
            
            # ç›´æ¥æ˜¾ç¤ºå¼¹çª—
            await self._show_alert_popup()
            
            print("[æˆåŠŸ] è­¦æŠ¥ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼š5å£°è­¦æŠ¥ + å¼¹çª— + UIæš‚åœçŠ¶æ€")
            
            # ğŸ”¥ æ–°å¢ï¼šç­‰å¾…ç”¨æˆ·é€šè¿‡UIç»§ç»­ç¨‹åº
            await self._wait_for_ui_resume()
            
        except Exception as e:
            print(f"[é”™è¯¯] å¯åŠ¨è­¦æŠ¥ç³»ç»Ÿå¤±è´¥: {e}")

    async def _create_pause_flag_for_ui(self):
        """åˆ›å»ºæš‚åœæ ‡å¿—æ–‡ä»¶ï¼Œè®©UIæ˜¾ç¤ºæš‚åœçŠ¶æ€"""
        try:
            # æ„å»ºæš‚åœæ ‡å¿—æ–‡ä»¶è·¯å¾„
            pause_flag_file = self.output_dir / "pause_flag.txt"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            pause_flag_file.parent.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºæš‚åœæ ‡å¿—æ–‡ä»¶
            with open(pause_flag_file, 'w', encoding='utf-8') as f:
                f.write(f"paused_at:{time.time()}")
            
            print(f"[æˆåŠŸ] å·²åˆ›å»ºæš‚åœæ ‡å¿—æ–‡ä»¶: {pause_flag_file}")
            print("ğŸ“± UIå°†æ˜¾ç¤ºæš‚åœçŠ¶æ€ï¼Œç”¨æˆ·å¯å³é”®ç‚¹å‡»'ç»§ç»­ç¨‹åº'")
            
        except Exception as e:
            print(f"[è­¦å‘Š] åˆ›å»ºæš‚åœæ ‡å¿—æ–‡ä»¶å¤±è´¥: {e}")

    async def _wait_for_ui_resume(self):
        """ç­‰å¾…ç”¨æˆ·é€šè¿‡UIç»§ç»­ç¨‹åº"""
        try:
            print("â³ ç­‰å¾…ç”¨æˆ·é€šè¿‡UIç»§ç»­ç¨‹åº...")
            
            # æ„å»ºæš‚åœæ ‡å¿—æ–‡ä»¶è·¯å¾„
            pause_flag_file = self.output_dir / "pause_flag.txt"
            
            # ç­‰å¾…æš‚åœæ ‡å¿—æ–‡ä»¶è¢«åˆ é™¤ï¼ˆç”¨æˆ·ç‚¹å‡»UIç»§ç»­ç¨‹åºï¼‰
            while pause_flag_file.exists():
                await asyncio.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œä½†ä¸è¾“å‡ºæ—¥å¿—
            
            print("[æˆåŠŸ] æ£€æµ‹åˆ°UIç»§ç»­ç¨‹åºä¿¡å·ï¼Œæ¢å¤è„šæœ¬æ‰§è¡Œ")
            
        except Exception as e:
            print(f"[è­¦å‘Š] ç­‰å¾…UIç»§ç»­ç¨‹åºå¤±è´¥: {e}")

    async def _play_alarm_sound(self):
        """ğŸ”¥ æ’­æ”¾5å£°è­¦æŠ¥å£°éŸ³"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ’­æ”¾è¿‡è­¦æŠ¥
            if self._alarm_played:
                print("ğŸ”Š è­¦æŠ¥å·²æ’­æ”¾è¿‡ï¼Œè·³è¿‡é‡å¤æ’­æ”¾")
                return
            
            # æ ‡è®°ä¸ºå·²æ’­æ”¾
            self._alarm_played = True
            print("ğŸ”Š å¼€å§‹æ’­æ”¾5å£°è­¦æŠ¥...")
            
            def play_sound():
                try:
                    import winsound
                    # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿åœ¨UIç¯å¢ƒä¸‹ä¹Ÿèƒ½æ’­æ”¾å£°éŸ³
                    for i in range(5):
                        winsound.Beep(1000, 500)  # 1000Hz, 0.5ç§’
                        time.sleep(0.1)  # çŸ­æš‚é—´éš”
                    print("ğŸ”Š 5å£°è­¦æŠ¥æ’­æ”¾å®Œæˆ")
                except Exception as e:
                    print(f"[è­¦å‘Š] æ’­æ”¾å£°éŸ³å¼‚å¸¸: {e}")
                    # ğŸ”¥ æ–°å¢ï¼šå¤‡ç”¨å£°éŸ³æ–¹æ¡ˆ
                    try:
                        import os
                        # ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ’­æ”¾å£°éŸ³
                        os.system('echo -e "\a\a\a\a\a"')  # 5æ¬¡èœ‚é¸£
                        print("ğŸ”Š ä½¿ç”¨å¤‡ç”¨å£°éŸ³æ–¹æ¡ˆå®Œæˆ")
                    except Exception as e2:
                        print(f"[è­¦å‘Š] å¤‡ç”¨å£°éŸ³æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
            
            # å¯åŠ¨å£°éŸ³çº¿ç¨‹
            sound_thread = threading.Thread(target=play_sound, daemon=True)
            sound_thread.start()
            
        except Exception as e:
            print(f"[è­¦å‘Š] æ’­æ”¾å£°éŸ³å¤±è´¥: {e}")

    async def _show_alert_popup(self):
        """ğŸ”¥ æ˜¾ç¤ºè­¦æŠ¥å¼¹çª—"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¾ç¤ºè¿‡å¼¹çª—
            if self._popup_shown:
                print("ğŸ“¢ å¼¹çª—å·²æ˜¾ç¤ºè¿‡ï¼Œè·³è¿‡é‡å¤æ˜¾ç¤º")
                return
            
            # æ ‡è®°ä¸ºå·²æ˜¾ç¤º
            self._popup_shown = True
            print("ğŸ“¢ æ˜¾ç¤ºè­¦æŠ¥å¼¹çª—...")
            
            def show_popup():
                try:
                    import tkinter as tk
                    from tkinter import messagebox
                    
                    # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿åœ¨UIç¯å¢ƒä¸‹ä¹Ÿèƒ½æ˜¾ç¤ºå¼¹çª—
                    try:
                        # åˆ›å»ºéšè—çš„æ ¹çª—å£
                        root = tk.Tk()
                        root.withdraw()  # éšè—ä¸»çª—å£
                        root.attributes('-topmost', True)  # ç½®é¡¶æ˜¾ç¤º
                        
                        # ğŸ”¥ æ–°å¢ï¼šå¼ºåˆ¶å¼¹çª—æ˜¾ç¤ºåœ¨å±å¹•ä¸­å¤®
                        # è·å–å±å¹•å°ºå¯¸
                        screen_width = root.winfo_screenwidth()
                        screen_height = root.winfo_screenheight()
                        
                        # è®¡ç®—å¼¹çª—ä½ç½®ï¼ˆå±å¹•ä¸­å¤®ï¼‰
                        popup_width = 400
                        popup_height = 300
                        x = (screen_width - popup_width) // 2
                        y = (screen_height - popup_height) // 2
                        
                        # è®¾ç½®å¼¹çª—ä½ç½®
                        root.geometry(f"{popup_width}x{popup_height}+{x}+{y}")
                        
                        # æ˜¾ç¤ºå¼¹çª—
                        messagebox.showwarning(
                            "ğŸš¨ ç³»ç»Ÿè­¦æŠ¥ - éœ€è¦äººå·¥å¤„ç†",
                            "è¯¦æƒ…é¡µæ•°æ®æŠ“å–å¤±è´¥ï¼\n\nå¯èƒ½åŸå› ï¼š\nâ€¢ é‡åˆ°æ»‘å—éªŒè¯\nâ€¢ ç½‘ç»œè¿æ¥é—®é¢˜\nâ€¢ é¡µé¢åŠ è½½å¼‚å¸¸\n\nè¯·äººå·¥éªŒè¯å¹¶å¤„ç†åç»§ç»­è¿è¡Œè„šæœ¬ã€‚"
                        )
                        
                        # é”€æ¯çª—å£
                        root.destroy()
                        
                        print("ğŸ“¢ å¼¹çª—å·²æ˜¾ç¤ºï¼šè¯·äººå·¥éªŒè¯å¤„ç†")
                        
                    except Exception as e:
                        print(f"[è­¦å‘Š] Tkinterå¼¹çª—å¤±è´¥: {e}")
                        # ğŸ”¥ æ–°å¢ï¼šå¤‡ç”¨å¼¹çª—æ–¹æ¡ˆ
                        try:
                            import subprocess
                            # ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ˜¾ç¤ºå¼¹çª—ï¼Œå¼ºåˆ¶æ˜¾ç¤ºåœ¨å±å¹•ä¸­å¤®
                            subprocess.run([
                                'powershell', 
                                '-Command', 
                                'Add-Type -AssemblyName System.Windows.Forms; $form = New-Object System.Windows.Forms.Form; $form.Text = "ğŸš¨ ç³»ç»Ÿè­¦æŠ¥"; $form.Size = New-Object System.Drawing.Size(400,300); $form.StartPosition = [System.Windows.Forms.FormStartPosition]::CenterScreen; $form.TopMost = $true; $label = New-Object System.Windows.Forms.Label; $label.Text = "è¯¦æƒ…é¡µæ•°æ®æŠ“å–å¤±è´¥ï¼\n\nè¯·äººå·¥éªŒè¯å¹¶å¤„ç†åç»§ç»­è¿è¡Œè„šæœ¬ã€‚"; $label.AutoSize = $true; $label.Location = New-Object System.Drawing.Point(20,20); $form.Controls.Add($label); $form.ShowDialog()'
                            ], shell=True)
                            print("ğŸ“¢ ä½¿ç”¨å¤‡ç”¨å¼¹çª—æ–¹æ¡ˆå®Œæˆ")
                        except Exception as e2:
                            print(f"[è­¦å‘Š] å¤‡ç”¨å¼¹çª—æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
                            
                except Exception as e:
                    print(f"[è­¦å‘Š] å¼¹çª—æ˜¾ç¤ºå¤±è´¥: {e}")
            
            # å¯åŠ¨å¼¹çª—çº¿ç¨‹
            popup_thread = threading.Thread(target=show_popup, daemon=True)
            popup_thread.start()
            
        except Exception as e:
            print(f"[è­¦å‘Š] å¯åŠ¨å¼¹çª—çº¿ç¨‹å¤±è´¥: {e}")

    def reset_alarm_status(self):
        """é‡ç½®è­¦æŠ¥çŠ¶æ€ï¼Œå…è®¸é‡æ–°æ’­æ”¾è­¦æŠ¥"""
        self._alarm_played = False
        self._popup_shown = False
        print("ğŸ”„ è­¦æŠ¥çŠ¶æ€å·²é‡ç½®ï¼Œå¯ä»¥é‡æ–°æ’­æ”¾")


    def _extract_goods_basic_info(self, raw_data: Dict) -> Dict[str, str]:
        """ğŸ”¥ æå–å•†å“åŸºæœ¬ä¿¡æ¯ç”¨äºæ—¥å¿—æ˜¾ç¤º"""
        try:
            info = {
                'name': 'æœªçŸ¥å•†å“',
                'price': 'æœªçŸ¥ä»·æ ¼',
                'sales': 'æœªçŸ¥é”€é‡'
            }

            # å°è¯•æå–å•†å“åç§°
            name_paths = [
                ['rawData', 'store', 'initDataObj', 'goods', 'goodsName'],
                ['rawData', 'store', 'initDataObj', 'goods', 'goods_name'],
                ['rawData', 'goods', 'goodsName'],
                ['rawData', 'goods', 'goods_name'],
                ['rawData', 'store', 'initDataObj', 'goods', 'title']
            ]

            for path in name_paths:
                try:
                    value = raw_data
                    for key in path:
                        value = value[key]
                    if value and isinstance(value, str):
                        info['name'] = value[:30] + ('...' if len(value) > 30 else '')  # é™åˆ¶é•¿åº¦
                        break
                except (KeyError, TypeError):
                    continue

            # å°è¯•æå–ä»·æ ¼
            price_paths = [
                ['rawData', 'store', 'initDataObj', 'goods', 'minOnSaleGroupPrice'],
                ['rawData', 'store', 'initDataObj', 'goods', 'price'],
                ['rawData', 'goods', 'price'],
                ['rawData', 'store', 'initDataObj', 'goods', 'marketPrice']
            ]

            for path in price_paths:
                try:
                    value = raw_data
                    for key in path:
                        value = value[key]
                    if value:
                        # ä»·æ ¼å¯èƒ½æ˜¯æ•°å­—æˆ–å­—ç¬¦ä¸²ï¼Œç»Ÿä¸€å¤„ç†
                        price_val = float(value) / 100 if isinstance(value, int) and value > 1000 else float(value)
                        info['price'] = f"Â¥{price_val:.2f}"
                        break
                except (KeyError, TypeError, ValueError):
                    continue

            # å°è¯•æå–é”€é‡
            sales_paths = [
                ['rawData', 'store', 'initDataObj', 'goods', 'soldQuantity'],
                ['rawData', 'store', 'initDataObj', 'goods', 'sales'],
                ['rawData', 'goods', 'soldQuantity'],
                ['rawData', 'goods', 'sales']
            ]

            for path in sales_paths:
                try:
                    value = raw_data
                    for key in path:
                        value = value[key]
                    if value is not None:
                        sales_num = int(value)
                        if sales_num >= 10000:
                            info['sales'] = f"{sales_num//10000}ä¸‡+"
                        else:
                            info['sales'] = str(sales_num)
                        break
                except (KeyError, TypeError, ValueError):
                    continue

            return info

        except Exception as e:
            print(f"[è­¦å‘Š] æå–å•†å“åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'name': 'æœªçŸ¥å•†å“',
                'price': 'æœªçŸ¥ä»·æ ¼',
                'sales': 'æœªçŸ¥é”€é‡'
            }

    async def _upload_to_server(self, goods_id: str, data: Dict) -> bool:
        """
        é¢„ç•™ï¼šåŠ å¯†ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨

        Args:
            goods_id: å•†å“ID
            data: è¦ä¸Šä¼ çš„æ•°æ®

        Returns:
            æ˜¯å¦ä¸Šä¼ æˆåŠŸ
        """
        # TODO: å®ç°åŠ å¯†ä¸Šä¼ é€»è¾‘
        # 1. åŠ å¯†æ•°æ®
        # 2. ä¸Šä¼ åˆ°æœåŠ¡å™¨
        # 3. è¿”å›ç»“æœ
        print(f"[é¢„ç•™] ä¸Šä¼ å•†å“ {goods_id} åˆ°æœåŠ¡å™¨ï¼ˆåŠŸèƒ½å¾…å®ç°ï¼‰")
        return True



    # ==================== ğŸ”¥ æ–°å¢ï¼šproduct_clickeré›†æˆæ‰€éœ€çš„æ–¹æ³• ====================

    def encrypt_compress_for_cloud(self, raw_data: Dict) -> Optional[Dict]:
        """
        äº‘ç«¯ä¸Šä¼ çš„åŠ å¯†å‹ç¼©æ–¹æ¡ˆ - ä¸æœåŠ¡å™¨ç«¯å®Œå…¨ä¸€è‡´
        ä½¿ç”¨ä¸pdd_server.pyç›¸åŒçš„åŠ å¯†é€»è¾‘

        Args:
            raw_data: åŸå§‹æ•°æ®

        Returns:
            åŒ…å«åŠ å¯†æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
            from cryptography.hazmat.backends import default_backend
            from cryptography.hazmat.primitives import hashes
            from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
            import lzma
            import base64
            import json

            # æœåŠ¡å™¨ç«¯ç›¸åŒçš„åŠ å¯†å¯†ç 
            USER_PASSWORD = "Ylw5555+Yufeizi-Haha23=SM"
            
            # ç”Ÿæˆä¸æœåŠ¡å™¨ç«¯å®Œå…¨ç›¸åŒçš„å¯†é’¥å’ŒIV
            def generate_keys_from_password(password):
                # ç”Ÿæˆ32å­—èŠ‚AESå¯†é’¥
                key_kdf = PBKDF2HMAC(
                    algorithm=hashes.SHA256(),
                    length=32,
                    salt=b'pdd_aes_key_salt_2025',
                    iterations=100000,
                )
                aes_key = key_kdf.derive(password.encode())
                
                # ç”Ÿæˆ16å­—èŠ‚IV
                iv_kdf = PBKDF2HMAC(
                    algorithm=hashes.SHA256(),
                    length=16,
                    salt=b'pdd_aes_iv_salt_2025',
                    iterations=50000,
                )
                aes_iv = iv_kdf.derive(password.encode())
                
                return aes_key, aes_iv
            
            AES_KEY, AES_IV = generate_keys_from_password(USER_PASSWORD)

            # è¶…ç´§å‡‘JSONå‹ç¼©ç®—æ³• - ä¸æœåŠ¡å™¨ç«¯å®Œå…¨ä¸€è‡´
            def ultra_compact_json(data):
                key_mapping = {
                    'goodsName': 'goo', 'originalPrice': 'ori', 'discount': 'dis',
                    'sales': 'sal', 'rating': 'rat', 'reviewCount': 'rev',
                    'shopName': 'sho', 'category': 'cat', 'description': 'des',
                    'imageUrl': 'img', 'detailUrl': 'url', 'brand': 'bra',
                    'specifications': 'spe', 'attributes': 'att', 'tags': 'tag',
                    'promotion': 'pro', 'shipping': 'shi', 'warranty': 'war',
                    'comments': 'com', 'questions': 'que', 'answers': 'ans'
                }
                
                important_keys = ['goods_id', 'goodsId', 'product_id', 'id', 'title', 'price', 'url']
                
                def compress_recursive(obj, depth=0):
                    if depth > 10:
                        return obj
                        
                    if isinstance(obj, dict):
                        compressed = {}
                        for key, value in obj.items():
                            if key in important_keys:
                                new_key = key
                            else:
                                new_key = key_mapping.get(key, key[:3] if len(key) > 3 else key)
                            
                            compressed_value = compress_recursive(value, depth + 1)
                            
                            if compressed_value not in [None, '', [], {}]:
                                compressed[new_key] = compressed_value
                                
                        return compressed
                        
                    elif isinstance(obj, list):
                        if len(obj) > 5:
                            return [compress_recursive(item, depth + 1) for item in obj[:5]]
                        else:
                            return [compress_recursive(item, depth + 1) for item in obj]
                            
                    elif isinstance(obj, str):
                        return obj[:200] if len(obj) > 200 else obj
                        
                    else:
                        return obj
                
                return compress_recursive(data)

            # AESåŠ å¯†å‡½æ•° - ä¸æœåŠ¡å™¨ç«¯å®Œå…¨ä¸€è‡´
            def aes_encrypt(data, key, iv):
                cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())
                encryptor = cipher.encryptor()
                
                # PKCS7å¡«å……
                block_size = 16
                padding_length = block_size - (len(data) % block_size)
                padded_data = data + bytes([padding_length] * padding_length)
                
                encrypted = encryptor.update(padded_data) + encryptor.finalize()
                return base64.b64encode(encrypted).decode('utf-8')

            # æ­¥éª¤1ï¼šä¿æŒåŸå§‹å®Œæ•´æ•°æ®ï¼ˆä¸ä½¿ç”¨è¶…ç´§å‡‘å‹ç¼©ï¼‰
            json_str = json.dumps(raw_data, ensure_ascii=False, separators=(',', ':'))
            original_size = len(json_str)
            
            # æ­¥éª¤2ï¼šLZMAå‹ç¼©ï¼ˆæœ€é«˜å‹ç¼©æ¯”ï¼‰
            compressed = lzma.compress(json_str.encode('utf-8'), preset=9)
            compressed_size = len(compressed)
            
            # æ­¥éª¤3ï¼šAESåŠ å¯†
            encrypted = aes_encrypt(compressed, AES_KEY, AES_IV)
            final_size = len(encrypted)

            # 4. è®¡ç®—å‹ç¼©ç‡
            compression_ratio = f"{(1 - final_size / original_size) * 100:.1f}%"

            # ğŸ”¥ åªæ˜¾ç¤ºä¿å­˜æˆåŠŸçš„æ—¥å¿—ï¼Œå…¶ä»–ä¸æ˜¾ç¤º
            # print(f"[åŠ å¯†] å®Œæˆ: {compression_ratio}")

            return {
                'encrypted_data': encrypted,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'final_size': final_size,
                'compression_ratio': compression_ratio,
                'encryption_method': 'AES-256 + LZMA + å®Œæ•´JSON'
            }

        except Exception as e:
            print(f"[é”™è¯¯] æ•°æ®åŠ å¯†å‹ç¼©å¤±è´¥: {e}")
            return None

    async def upload_to_server(self, encrypted_data: str, goods_id: str) -> bool:
        """
        ä¸Šä¼ åŠ å¯†æ•°æ®åˆ°çœŸå®æœåŠ¡å™¨

        Args:
            encrypted_data: åŠ å¯†åçš„æ•°æ®
            goods_id: å•†å“ID

        Returns:
            æ˜¯å¦ä¸Šä¼ æˆåŠŸ
        """
        try:
            import requests
            import asyncio
            
            # è·å–æœåŠ¡å™¨é…ç½®
            cloud_config = self.config_mgr.get_config().get('cloud_server', {})
            server_url = cloud_config.get('server_url', 'http://localhost:8888')
            client_id = cloud_config.get('client_id', 'PDD_CLIENT_001')
            
            # æ„å»ºä¸Šä¼ æ•°æ®
            upload_data = {
                'goods_id': goods_id,
                'encrypted_data': encrypted_data,
                'browser_id': self.browser_id,
                'client_id': client_id,
                'timestamp': datetime.now().isoformat(),
                'encryption': 'AES-256 + LZMA + è¶…ç´§å‡‘JSON'
            }
            
            # å‘é€POSTè¯·æ±‚åˆ°æœåŠ¡å™¨
            def sync_upload():
                # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®server_urlè‡ªåŠ¨åˆ¤æ–­ç«¯ç‚¹è·¯å¾„
                if server_url.endswith('/api'):
                    upload_endpoint = f"{server_url}/upload"
                elif '/api/' in server_url:
                    upload_endpoint = server_url  # server_urlå·²åŒ…å«å®Œæ•´è·¯å¾„
                else:
                    upload_endpoint = f"{server_url}/upload"
                    
                response = requests.post(
                    upload_endpoint,
                    json=upload_data,
                    timeout=30,
                    headers={'Content-Type': 'application/json'}
                )
                return response
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, sync_upload)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('status') == 'success':
                    return True
                else:
                    print(f"[é”™è¯¯] æœåŠ¡å™¨è¿”å›é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return False
            else:
                print(f"[é”™è¯¯] æœåŠ¡å™¨å“åº”é”™è¯¯: HTTP {response.status_code}")
                return False

        except Exception as e:
            print(f"[é”™è¯¯] ä¸Šä¼ åˆ°æœåŠ¡å™¨å¤±è´¥: {e}")
            return False

    async def download_and_save_from_server(self, goods_id: str, original_data: dict = None) -> bool:
        """ä»æœåŠ¡å™¨ä¸‹è½½æ•°æ®å¹¶ä¿å­˜"""
        try:
            import requests
            import asyncio
            import json

            # é¢„å”®æ£€æµ‹
            if original_data:
                presale_info = self._extract_presale_info(original_data)
                if presale_info:
                    return True

            # è·å–æœåŠ¡å™¨é…ç½®
            config = self.config_mgr.get_config()
            cloud_config = config.get('cloud_server', {})
            server_config = config.get('server_config', {})
            
            # ä¼˜å…ˆä½¿ç”¨cloud_server.server_urlï¼Œå…¶æ¬¡ä½¿ç”¨server_config.upload_url
            server_url = cloud_config.get('server_url') or server_config.get('upload_url', 'http://localhost:8888')
            
            # æ„å»ºä¸‹è½½åœ°å€
            if server_url.endswith('/api'):
                download_endpoint = f"{server_url}/download/{goods_id}"
            elif '/upload' in server_url:
                download_endpoint = server_url.replace('/upload', f'/download/{goods_id}')
            else:
                download_endpoint = f"{server_url}/download/{goods_id}"

            # ä¸‹è½½æ•°æ®
            import aiohttp
            
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(download_endpoint) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data:
                            # ç¡®ä¿detailsç›®å½•å­˜åœ¨
                            import os
                            from pathlib import Path
                            current_file_dir = os.path.dirname(os.path.abspath(__file__))
                            project_root = current_file_dir
                            while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                                parent = os.path.dirname(project_root)
                                if parent == project_root:
                                    break
                                project_root = parent
                            
                            details_dir = Path(project_root) / "details"
                            details_dir.mkdir(exist_ok=True)
                            
                            # ä¿å­˜æ•°æ®ä¸ºTXTæ–‡æ¡£ï¼ˆä»¥å•†å“IDå‘½åï¼‰
                            txt_file = details_dir / f"{goods_id}.txt"
                            with open(txt_file, 'w', encoding='utf-8') as f:
                                json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
                                f.write(json_str)
                            
                            # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
                            if not (txt_file.exists() and txt_file.stat().st_size > 0):
                                return False
                            
                            # æ›´æ–°ç»Ÿè®¡
                            self.runtime_parsed_count += 1
                            self._update_runtime_stats()
                            
                            # ä¿å­˜CSVæ•°æ®
                            if original_data:
                                csv_data = self._extract_csv_fields(original_data)
                                if csv_data and csv_data.get('å•†å“ID'):
                                    self._save_to_csv_without_count_update(csv_data.copy())
                            
                            return True
                    else:
                        return False

        except Exception as e:
            return False

    # ==================== äº‘ç«¯ä¸Šä¼ åŠŸèƒ½ï¼ˆå·²é›†æˆåˆ°suoyin.pyï¼‰ ====================
    # ğŸ”¥ æœ¬åœ°ä¿å­˜åŠŸèƒ½å·²åˆ é™¤ - æ•°æ®ç›´æ¥é€šè¿‡suoyin.pyåŠ å¯†ä¸Šä¼ åˆ°æœåŠ¡å™¨
    # ğŸ”¥ Excelå¯¼å‡ºåŠŸèƒ½å·²åˆ é™¤ - é¿å…é‡å¤çš„Excelå¯¼å‡ºï¼Œä½¿ç”¨ç»Ÿä¸€çš„ä¿å­˜æœºåˆ¶

    # ==================== ğŸ”¥ æ–°å¢ï¼šCSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½ ====================
    
    def _init_csv_functionality(self):
        """åˆå§‹åŒ–CSVä¿å­˜å’Œè¿è¡Œæ—¶ç»Ÿè®¡åŠŸèƒ½"""
        try:
            # è¿è¡Œæ—¶ç»Ÿè®¡åˆå§‹åŒ–
            self.runtime_parsed_count = 0
            
            # ğŸ”¥ æ–°ç‰ˆè·¯å¾„ï¼šä¿å­˜åˆ°ä¸»ç›®å½•çš„outputå’Œcacheæ–‡ä»¶å¤¹
            # æ‰¾åˆ°ä¸»ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
            current_file_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = current_file_dir
            
            # å‘ä¸ŠæŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å«generated_scriptsçš„ç›®å½•ï¼‰
            while project_root and not os.path.exists(os.path.join(project_root, "generated_scripts")):
                parent = os.path.dirname(project_root)
                if parent == project_root:  # å·²ç»åˆ°è¾¾æ ¹ç›®å½•
                    break
                project_root = parent
            
            # åˆ›å»ºä¸»ç›®å½•çš„outputå’Œcacheæ–‡ä»¶å¤¹
            main_output_dir = Path(project_root) / "output"
            main_cache_dir = Path(project_root) / "cache"
            main_output_dir.mkdir(exist_ok=True)
            main_cache_dir.mkdir(exist_ok=True)
            
            # CSVæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åˆ°ä¸»ç›®å½•outputæ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶ååŠ ä¸Šæµè§ˆå™¨IDï¼‰
            self.csv_file_path = main_output_dir / f"å•†å“æ•°æ®_{self.browser_id}.csv"
            
            # ç»Ÿè®¡JSONæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åˆ°ä¸»ç›®å½•cacheæ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶ååŠ ä¸Šæµè§ˆå™¨IDï¼‰
            self.stats_file_path = main_cache_dir / f"ç»Ÿè®¡æ•°é‡_{self.browser_id}.json"
            
            # åˆ›å»ºCSVæ–‡ä»¶å¤´ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰
            self._create_csv_header()
            
            # åˆå§‹åŒ–ç»Ÿè®¡JSONæ–‡ä»¶
            self._init_stats_file()
            
            print(f"[CSV] CSVåŠŸèƒ½å·²åˆå§‹åŒ–ï¼ˆæ–°ç‰ˆè·¯å¾„ï¼‰")
            print(f"[CSV] ä¸»ç›®å½•output: {main_output_dir}")
            print(f"[CSV] ä¸»ç›®å½•cache: {main_cache_dir}")
            print(f"[CSV] CSVæ–‡ä»¶: {self.csv_file_path}")
            print(f"[CSV] ç»Ÿè®¡æ–‡ä»¶: {self.stats_file_path}")
            
        except Exception as e:
            print(f"[é”™è¯¯] CSVåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _create_csv_header(self):
        """åˆ›å»ºCSVæ–‡ä»¶å¤´ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰"""
        try:
            if not self.csv_file_path.exists():
                headers = [
                    "å•†å“ID", "å•†å“åç§°", "å•†å“é“¾æ¥", "å½“å‰ä»·æ ¼", "åˆ¸åä»·", "å•†å“é”€é‡", "åº—é“ºé”€é‡", 
                    "é«˜æ¸…å›¾ç‰‡", "å•†å®¶ID", "åº—é“ºåç§°", "å‘è´§æ—¶é—´", "å‘è´§åœ°", "å•†å“ç±»ç›®", "è¯„ä»·æ•°é‡", "æ­£åœ¨æ‹¼", "åº—é“ºå•†å“æ•°é‡", "éƒ¨åˆ†é¢„å”®", "24å°æ—¶å‘è´§", "æ–°å“", "ä¸Šæ¶æ—¶é—´", "é‡‡é›†æ—¶é—´"
                ]
                
                import csv
                with open(self.csv_file_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    writer.writerow(headers)
                print(f"[CSV] CSVæ–‡ä»¶å¤´å·²åˆ›å»º")
        except Exception as e:
            print(f"[é”™è¯¯] åˆ›å»ºCSVæ–‡ä»¶å¤´å¤±è´¥: {e}")
    
    def _init_stats_file(self):
        """åˆå§‹åŒ–ç»Ÿè®¡JSONæ–‡ä»¶"""
        try:
            stats_data = {
                "è§£ææ•°é‡": self.runtime_parsed_count,
                "æœ€åæ›´æ–°": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            with open(self.stats_file_path, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
            
            print(f"[CSV] ç»Ÿè®¡æ–‡ä»¶å·²åˆå§‹åŒ–: {self.runtime_parsed_count}ä¸ª")
        except Exception as e:
            print(f"[é”™è¯¯] åˆå§‹åŒ–ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")
    
    def _flexible_get(self, data: Dict, field_names: List[str], default_value=None):
        """çµæ´»è·å–å­—æ®µå€¼ï¼ˆå¿½ç•¥å¤§å°å†™å’Œ_ç¬¦å·ï¼‰"""
        try:
            # é¦–å…ˆå°è¯•ç›´æ¥åŒ¹é…
            for field_name in field_names:
                if field_name in data:
                    return data[field_name]
            
            # å¦‚æœç›´æ¥åŒ¹é…å¤±è´¥ï¼Œå°è¯•å¿½ç•¥å¤§å°å†™å’Œ_ç¬¦å·çš„åŒ¹é…
            data_keys = list(data.keys())
            for field_name in field_names:
                # æ ‡å‡†åŒ–å­—æ®µåï¼ˆç§»é™¤_ç¬¦å·ï¼Œè½¬å°å†™ï¼‰
                normalized_field = field_name.replace("_", "").lower()
                
                for data_key in data_keys:
                    normalized_data_key = data_key.replace("_", "").lower()
                    if normalized_field == normalized_data_key:
                        return data[data_key]
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨åµŒå¥—å¯¹è±¡ä¸­æŸ¥æ‰¾
            try:
                goods = data.get("store", {}).get("initDataObj", {}).get("goods", {})
                if goods:
                    for field_name in field_names:
                        if field_name in goods:
                            return goods[field_name]
                    
                    # åœ¨goodsä¸­ä¹Ÿå°è¯•å¿½ç•¥å¤§å°å†™åŒ¹é…
                    goods_keys = list(goods.keys())
                    for field_name in field_names:
                        normalized_field = field_name.replace("_", "").lower()
                        for goods_key in goods_keys:
                            normalized_goods_key = goods_key.replace("_", "").lower()
                            if normalized_field == normalized_goods_key:
                                return goods[goods_key]
            except:
                pass
            
            return default_value
        except Exception:
            return default_value

    def _safe_price_convert(self, price_value) -> float:
        """å®‰å…¨è½¬æ¢ä»·æ ¼å€¼"""
        try:
            if price_value is None or price_value == "":
                return 0.0
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(price_value, str):
                import re
                # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼ˆé™¤äº†å°æ•°ç‚¹ï¼‰
                price_str = re.sub(r"[^0-9.]", "", str(price_value))
                if price_str:
                    price_value = float(price_str)
                else:
                    return 0.0
            
            # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            price_float = float(price_value)
            
            # å¦‚æœä»·æ ¼å¤§äº1000ï¼Œå¯èƒ½æ˜¯åˆ†ä¸ºå•ä½ï¼Œéœ€è¦è½¬æ¢ä¸ºå…ƒ
            if price_float > 1000:
                return round(price_float / 100, 2)
            else:
                return round(price_float, 2)
                
        except Exception:
            return 0.0

    def _safe_int_convert(self, int_value) -> int:
        """å®‰å…¨è½¬æ¢æ•´æ•°å€¼"""
        try:
            if int_value is None or int_value == "":
                return 0
            
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæ•°å­—
            if isinstance(int_value, str):
                import re
                # ç§»é™¤éæ•°å­—å­—ç¬¦
                int_str = re.sub(r"[^0-9]", "", str(int_value))
                if int_str:
                    return int(int_str)
                else:
                    return 0
            
            return int(int_value)
        except Exception:
            return 0

    def _extract_csv_fields(self, raw_data: Dict) -> Optional[Dict]:
        """ä»rawDataæå–CSVéœ€è¦çš„å­—æ®µ"""
        try:
            if not raw_data or 'rawData' not in raw_data:
                return None
            
            data = raw_data['rawData']
            
            # ä»rawDataä¸­æå–goodså¯¹è±¡
            goods = data.get('store', {}).get('initDataObj', {}).get('goods', {})
            
            # æå–å›¾æ ‡ä¿¡æ¯
            icon_info = self._extract_icon_info(data)
            
            # æå–ä¸Šæ¶æ—¶é—´
            upload_time = self._extract_upload_time(data)
            
            # æŒ‰ç…§è¦æ±‚çš„å­—æ®µç»“æ„æ„å»ºCSVæ•°æ®
            csv_data = {
                'å•†å“ID': str(self._flexible_get(data, ['goodsID', 'goods_id', 'id'], '') or ''),
                'å•†å“åç§°': self._flexible_get(data, ['goodsName', 'goods_name', 'title'], '') or '',
                'å•†å“é“¾æ¥': raw_data.get('url', '') or '',
                'å½“å‰ä»·æ ¼': self._safe_price_convert(self._flexible_get(data, ['minOnSaleGroupPrice', 'price', 'min_price', 'current_price'], 0)),
                'åˆ¸åä»·': self._safe_price_convert(self._flexible_get(data, ['minOnSaleGroupPrice', 'coupon_price', 'price'], 0)),
                'å•†å“é”€é‡': self._extract_goods_sales(data) or 0,
                'åº—é“ºé”€é‡': self._extract_store_sales(data) or '',
                'é«˜æ¸…å›¾ç‰‡': self._flexible_get(data, ['hdThumbUrl', 'thumbUrl', 'image_url', 'thumb_url'], '') or '',
                'å•†å®¶ID': str(self._flexible_get(data, ['mallID', 'mall_id', 'merchant_id'], '') or ''),
                'åº—é“ºåç§°': self._extract_shop_name(data) or '',
                'å‘è´§æ—¶é—´': self._extract_delivery_time(data) or '',
                'å‘è´§åœ°': self._extract_delivery_location(data) or '',
                'å•†å“ç±»ç›®': self._extract_category_info(data) or '',
                'è¯„ä»·æ•°é‡': self._extract_review_count(data) or 0,
                'æ­£åœ¨æ‹¼': self._extract_grouping_info(data) or '',
                'åº—é“ºå•†å“æ•°é‡': self._extract_store_count(data) or '',
                'éƒ¨åˆ†é¢„å”®': self._extract_presale_info(data) or '',
                '24å°æ—¶å‘è´§': icon_info.get('has_24h_shipping', 'å¦'),
                'æ–°å“': icon_info.get('has_new_product', 'å¦'),
                'ä¸Šæ¶æ—¶é—´': upload_time or '',
                'é‡‡é›†æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return csv_data
            
        except Exception as e:
            print(f"[é”™è¯¯] æå–CSVå­—æ®µå¤±è´¥: {e}")
            return None
    
    def _extract_icon_info(self, data: Dict) -> Dict:
        """æå–å›¾æ ‡ç›¸å…³ä¿¡æ¯"""
        try:
            icon_info = {
                'has_24h_shipping': 'å¦',
                'has_new_product': 'å¦'
            }
            
            # ä»å•†å“å±æ€§ä¸­æå–å›¾æ ‡ä¿¡æ¯
            goods_property = data.get('store', {}).get('initDataObj', {}).get('goods', {}).get('goodsProperty', [])
            
            for prop in goods_property:
                if prop.get('key') == '24å°æ—¶å‘è´§':
                    icon_info['has_24h_shipping'] = 'æ˜¯'
                elif prop.get('key') == 'æ–°å“':
                    icon_info['has_new_product'] = 'æ˜¯'
            
            return icon_info
        except Exception:
            return {
                'has_24h_shipping': 'å¦',
                'has_new_product': 'å¦'
            }
    
    
    
    def _extract_category_info(self, data: Dict) -> str:
        """æå–å•†å“åˆ†ç±»ä¿¡æ¯"""
        try:
            # å°è¯•è·å–åˆ†ç±»é“¾
            cat1 = self._flexible_get(data, ['cat1Name', 'category1', 'catName1'], '')
            cat2 = self._flexible_get(data, ['cat2Name', 'category2', 'catName2'], '')
            cat3 = self._flexible_get(data, ['cat3Name', 'category3', 'catName3'], '')
            
            # æ„å»ºåˆ†ç±»é“¾
            categories = [cat for cat in [cat1, cat2, cat3] if cat]
            return ' > '.join(categories) if categories else ''
        except:
            return ''
    

    def _extract_upload_time(self, data: Dict) -> str:
        """æå–ä¸Šæ¶æ—¶é—´"""
        try:
            # ä»é«˜æ¸…å›¾ç‰‡URLä¸­æå–æ—¶é—´
            goods = data.get('store', {}).get('initDataObj', {}).get('goods', {})
            hd_thumb_url = goods.get('hdThumbUrl', '')
            thumb_url = goods.get('thumbUrl', '')
            
            # ä¼˜å…ˆä½¿ç”¨é«˜æ¸…å›¾ç‰‡URLï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ™®é€šå›¾ç‰‡URL
            url = hd_thumb_url if hd_thumb_url else thumb_url
            
            if url:
                import re
                # ä»URLä¸­æå–æ—¥æœŸï¼Œæ ¼å¼å¦‚ï¼š2025-07-12
                match = re.search(r'/(\d{4}-\d{2}-\d{2})/', url)
                if match:
                    return match.group(1)
            
            return ''
        except Exception:
            return ''
    
    def _extract_delivery_time(self, data: Dict) -> str:
        """æå–å‘è´§æ—¶é—´ï¼ˆdeliveryTimeå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å‘è´§æ—¶é—´
            delivery_time_paths = [
                ['store', 'initDataObj', 'ui', 'deliveryTimeV2Section', 'mainText'],
                ['store', 'initDataObj', 'shipping', 'deliveryTime'],
                ['shipping', 'deliveryTime'],
                ['deliveryTime']
            ]
            
            for path in delivery_time_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_shop_name(self, data: Dict) -> str:
        """æå–åº—é“ºåç§°ï¼ˆmallNameå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºåç§°
            shop_name_paths = [
                ['store', 'initDataObj', 'mall', 'mallName'],
                ['mall', 'mallName'],
                ['mallName']
            ]
            
            for path in shop_name_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_presale_info(self, data: Dict) -> str:
        """æå–éƒ¨åˆ†é¢„å”®ä¿¡æ¯ï¼ˆclick_noticeå­—æ®µï¼‰ï¼Œåªè¦å­—æ®µå­˜åœ¨å°±è·³è¿‡ä¿å­˜"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–é¢„å”®ä¿¡æ¯
            presale_paths = [
                ['store', 'initDataObj', 'goods', 'click_notice'],
                ['goods', 'click_notice'],
                ['click_notice']
            ]
            
            for path in presale_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        # åªè¦click_noticeå­—æ®µå­˜åœ¨ä¸”æœ‰å†…å®¹ï¼Œå°±è¿”å›è¯¥å†…å®¹ï¼ˆåç»­ä¼šè·³è¿‡ä¿å­˜ï¼‰
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''  # å­—æ®µä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆæ­£å¸¸ä¿å­˜ï¼‰
        except Exception:
            return ''

    def _extract_delivery_location(self, data: Dict) -> str:
        """æå–å‘è´§åœ°ï¼ˆshippingLocationå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å‘è´§åœ°
            location_paths = [
                ['store', 'initDataObj', 'ui', 'deliveryTimeV2Section', 'subText'],
                ['store', 'initDataObj', 'shipping', 'shippingLocation'],
                ['store', 'initDataObj', 'shipping', 'originPlace'],
                ['shipping', 'originPlace'],
                ['shipping', 'shippingLocation'],
                ['shippingLocation'],
                ['originPlace']
            ]
            
            for path in location_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»UIæ–‡æœ¬ä¸­æå–å‘è´§åœ°
            try:
                delivery_section = data.get('store', {}).get('initDataObj', {}).get('ui', {}).get('deliveryTimeV2Section', {})
                sub_text = delivery_section.get('subText', '')
                if 'å‘è´§' in sub_text:
                    import re
                    match = re.search(r'(.+?)å‘è´§', sub_text)
                    if match:
                        return match.group(1)
            except:
                pass
                    
            return ''
        except Exception:
            return ''

    def _extract_category_info(self, data: Dict) -> str:
        """æå–å•†å“ç±»ç›®"""
        try:
            cat_names = []
            
            # æŒ‰é¡ºåºæå–cat1Nameåˆ°cat4Name
            for i in range(1, 5):
                cat_name_paths = [
                    ['store', 'initDataObj', 'goods', f'cat{i}Name'],
                    ['goods', f'cat{i}Name'],
                    [f'cat{i}Name']
                ]
                
                for path in cat_name_paths:
                    try:
                        value = data
                        for key in path:
                            value = value[key]
                        if value is not None and value != '':
                            cat_names.append(str(value))
                            break
                    except (KeyError, TypeError):
                        continue
            
            # æŒ‰ç…§é¡ºåºè¿æ¥ï¼Œæ²¡æœ‰çš„åˆ†ç±»ä¸æ˜¾ç¤º
            return '-'.join(cat_names) if cat_names else ''
        except Exception:
            return ''

    def _extract_review_count(self, data: Dict) -> int:
        """æå–è¯„ä»·æ•°é‡ï¼ˆreviewNumå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–è¯„ä»·æ•°é‡
            review_paths = [
                ['store', 'initDataObj', 'review', 'reviewNum'],
                ['review', 'reviewNum'],
                ['reviewNum']
            ]
            
            for path in review_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return int(value) if value else 0
                except (KeyError, TypeError, ValueError):
                    continue
                    
            return 0
        except Exception:
            return 0

    def _extract_goods_sales(self, data: Dict) -> int:
        """æå–å•†å“é”€é‡ï¼ˆsideSalesTipï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–å•†å“é”€é‡
            sales_paths = [
                ['store', 'initDataObj', 'goods', 'sideSalesTip'],
                ['store', 'initDataObj', 'goods', 'soldQuantity'],
                ['store', 'initDataObj', 'goods', 'sales'],
                ['goods', 'sideSalesTip'],
                ['goods', 'soldQuantity'],
                ['goods', 'sales'],
                ['sideSalesTip'],
                ['soldQuantity']
            ]
            
            for path in sales_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return self._safe_int_convert(value)
                except (KeyError, TypeError):
                    continue
                    
            return 0
        except Exception:
            return 0

    def _extract_store_sales(self, data: Dict) -> str:
        """æå–åº—é“ºé”€é‡ï¼ˆsalesTipï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºé”€é‡æç¤º
            sales_tip_paths = [
                ['store', 'initDataObj', 'goods', 'salesTip'],
                ['store', 'initDataObj', 'goods', 'sales_tip'],
                ['goods', 'salesTip'],
                ['goods', 'sales_tip'],
                ['salesTip'],
                ['sales_tip']
            ]
            
            for path in sales_tip_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_grouping_info(self, data: Dict) -> str:
        """æå–æ­£åœ¨æ‹¼æ•°é‡ï¼ˆgroupsTotalå­—æ®µï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–æ­£åœ¨æ‹¼æ•°é‡
            grouping_paths = [
                ['store', 'initDataObj', 'groupingInfo', 'groupsTotal'],
                ['store', 'initDataObj', 'groupingInfo', 'groupingNum'],
                ['groupingInfo', 'groupsTotal'],
                ['groupingInfo', 'groupingNum'],
                ['groupsTotal'],
                ['groupingNum']
            ]
            
            for path in grouping_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        return str(value)
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _extract_store_count(self, data: Dict) -> str:
        """æå–åº—é“ºæ•°é‡ï¼ˆgoodsNumDescï¼Œå»æ‰'å•†å“æ•°é‡ï¼š'åªç•™æ•°å­—ï¼‰"""
        try:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–åº—é“ºå•†å“æ•°é‡æè¿°
            store_count_paths = [
                ['store', 'initDataObj', 'goods', 'goodsNumDesc'],
                ['store', 'initDataObj', 'mall', 'goodsNumDesc'],
                ['goods', 'goodsNumDesc'],
                ['goodsNumDesc']
            ]
            
            for path in store_count_paths:
                try:
                    value = data
                    for key in path:
                        value = value[key]
                    if value is not None and value != '':
                        raw_value = str(value)
                        # å»æ‰"å•†å“æ•°é‡ï¼š"å‰ç¼€ï¼Œåªä¿ç•™æ•°å­—
                        import re
                        # æå–æ•°å­—éƒ¨åˆ†
                        numbers = re.findall(r'\d+', raw_value)
                        if numbers:
                            return numbers[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ•°å­—
                        return raw_value  # å¦‚æœæ²¡æœ‰æ•°å­—ï¼Œè¿”å›åŸå§‹å€¼
                except (KeyError, TypeError):
                    continue
                    
            return ''
        except Exception:
            return ''

    def _save_to_csv(self, csv_data: Dict) -> bool:
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶ï¼ˆå¢é‡è¿½åŠ ï¼‰"""

        try:
            import csv
            
            # æŒ‰ç…§CSVå¤´çš„é¡ºåºå‡†å¤‡æ•°æ®
            headers = [
                "å•†å“ID", "å•†å“åç§°", "å•†å“é“¾æ¥", "å½“å‰ä»·æ ¼", "åˆ¸åä»·", "å•†å“é”€é‡", "åº—é“ºé”€é‡", 
                "é«˜æ¸…å›¾ç‰‡", "å•†å®¶ID", "åº—é“ºåç§°", "å‘è´§æ—¶é—´", "å‘è´§åœ°", "å•†å“ç±»ç›®", "è¯„ä»·æ•°é‡", "æ­£åœ¨æ‹¼", "åº—é“ºå•†å“æ•°é‡", "éƒ¨åˆ†é¢„å”®", "24å°æ—¶å‘è´§", "æ–°å“", "ä¸Šæ¶æ—¶é—´", "é‡‡é›†æ—¶é—´"
            ]
            
            row_data = [csv_data.get(header, '') for header in headers]
            
            # è¿½åŠ åˆ°CSVæ–‡ä»¶
            with open(self.csv_file_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
            
            # æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡
            self.runtime_parsed_count += 1
            self._update_runtime_stats()
            
            return True
            
        except Exception as e:
            print(f"[é”™è¯¯] ä¿å­˜CSVæ•°æ®å¤±è´¥: {e}")
            return False

    def _save_to_csv_without_count_update(self, csv_data: Dict) -> bool:
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶ï¼ˆå¢é‡è¿½åŠ ï¼‰- ä¸æ›´æ–°ç»Ÿè®¡è®¡æ•°"""
        try:
            import csv
            
            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿CSVæ–‡ä»¶å¤´å­˜åœ¨
            self._create_csv_header()
            
            # æŒ‰ç…§CSVå¤´çš„é¡ºåºå‡†å¤‡æ•°æ®
            headers = [
                "å•†å“ID", "å•†å“åç§°", "å•†å“é“¾æ¥", "å½“å‰ä»·æ ¼", "åˆ¸åä»·", "å•†å“é”€é‡", "åº—é“ºé”€é‡", 
                "é«˜æ¸…å›¾ç‰‡", "å•†å®¶ID", "åº—é“ºåç§°", "å‘è´§æ—¶é—´", "å‘è´§åœ°", "å•†å“ç±»ç›®", "è¯„ä»·æ•°é‡", "æ­£åœ¨æ‹¼", "åº—é“ºå•†å“æ•°é‡", "éƒ¨åˆ†é¢„å”®", "24å°æ—¶å‘è´§", "æ–°å“", "ä¸Šæ¶æ—¶é—´", "é‡‡é›†æ—¶é—´"
            ]
            
            row_data = [csv_data.get(header, '') for header in headers]
            
            # è¿½åŠ åˆ°CSVæ–‡ä»¶
            with open(self.csv_file_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(row_data)
            
            # ğŸ”¥ æ³¨æ„ï¼šè¿™é‡Œä¸æ›´æ–°ç»Ÿè®¡è®¡æ•°ï¼Œé¿å…é‡å¤è®¡æ•°
            
            return True
            
        except Exception as e:
            print(f"[é”™è¯¯] ä¿å­˜CSVæ•°æ®å¤±è´¥: {e}")
            return False
    
    def _update_runtime_stats(self):
        """æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡"""
        try:
            stats_data = {
                "è§£ææ•°é‡": self.runtime_parsed_count,
                "æœ€åæ›´æ–°": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            with open(self.stats_file_path, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š å·²è§£æ: {self.runtime_parsed_count}ä¸ª")
            
        except Exception as e:
            print(f"[é”™è¯¯] æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡å¤±è´¥: {e}")

# ==================== å…¨å±€æ¥å£ ====================

# ğŸ”¥ å¤šæµè§ˆå™¨å®ä¾‹ç®¡ç†ï¼ˆé¿å…å…¨å±€å•ä¾‹å†²çªï¼‰
_extractor_instances = {}

def get_extractor(browser_id: str = None) -> DetailPageExtractor:
    """è·å–æŠ“å–å™¨å®ä¾‹ï¼ˆæ¯ä¸ªæµè§ˆå™¨ç‹¬ç«‹å®ä¾‹ï¼‰"""
    if browser_id is None:
        # å¦‚æœæ²¡æœ‰æä¾›browser_idï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶è·å–
        try:
            from config_manager import ConfigManager
            config_mgr = ConfigManager()
            browser_id = config_mgr.get_browser_id()
        except:
            browser_id = "default"

    # ä¸ºæ¯ä¸ªæµè§ˆå™¨åˆ›å»ºç‹¬ç«‹å®ä¾‹
    if browser_id not in _extractor_instances:
        _extractor_instances[browser_id] = DetailPageExtractor(browser_id)

    return _extractor_instances[browser_id]

async def extract_and_save(page, browser_id: str = None) -> bool:
        """
        ä¾¿æ·å‡½æ•°ï¼šæŠ“å–å¹¶ä¿å­˜è¯¦æƒ…é¡µæ•°æ®

        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            browser_id: æµè§ˆå™¨ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        extractor = get_extractor(browser_id)

        # è®¾ç½®ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        extractor.set_task_status("detail_running", True)

        try:
            result = await extractor.process_detail_page(page)
            return result
        finally:
            # æ¸…é™¤ä»»åŠ¡çŠ¶æ€
            extractor.set_task_status("detail_running", False)

def is_product_clicked(product_id: str, browser_id: str = None) -> bool:
    """
    æ£€æŸ¥å•†å“æ˜¯å¦å·²è¢«ç‚¹å‡»è¿‡ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰

    Args:
        product_id: å•†å“ID
        browser_id: æµè§ˆå™¨ID

    Returns:
        æ˜¯å¦å·²è¢«ç‚¹å‡»è¿‡
    """
    extractor = get_extractor(browser_id)
    return extractor.is_product_clicked(product_id)

def get_clicked_products_count(browser_id: str = None) -> int:
    """
    è·å–å·²ç‚¹å‡»å•†å“æ•°é‡ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰

    Args:
        browser_id: æµè§ˆå™¨ID

    Returns:
        å·²ç‚¹å‡»å•†å“æ•°é‡
    """
    extractor = get_extractor(browser_id)
    return len(extractor.clicked_products)

async def main():
    """ç‹¬ç«‹è¿è¡Œæ¨¡å¼ - å¤„ç†å·²ç‚¹å‡»çš„å•†å“è¯¦æƒ…é¡µæ•°æ®"""
    print("ğŸ” è¯¦æƒ…é¡µæ•°æ®æŠ“å–æ¨¡å—")
    print("=" * 50)

    try:
        # è‡ªåŠ¨æ£€æµ‹æµè§ˆå™¨ID
        import os
        current_dir = os.getcwd()
        if "browser_" in current_dir:
            browser_id = current_dir.split("browser_")[-1]
        else:
            browser_id = "default"

        print(f"ğŸ“‹ æµè§ˆå™¨ID: {browser_id[-6:]}")

        # è·å–æå–å™¨å®ä¾‹
        extractor = get_extractor(browser_id)

        # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šç­‰å¾…ä¸Šä¸€ä¸ªä»»åŠ¡å®Œæˆ
        extractor.wait_for_previous_task()

        # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šè®¾ç½®å½“å‰ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        extractor.set_task_status("detail_running", True)

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç‚¹å‡»çš„å•†å“éœ€è¦å¤„ç†
            clicked_count = len(extractor.clicked_products)
            print(f"ğŸ“Š å·²ç‚¹å‡»å•†å“æ•°é‡: {clicked_count}")

            # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè¯¦æƒ…æ•°æ®ç›®å½•çŠ¶æ€
            print(f"ğŸ“ è¯¦æƒ…æ•°æ®ç›®å½•: {extractor.details_dir}")
            print(f"ğŸ“ ç›®å½•æ˜¯å¦å­˜åœ¨: {extractor.details_dir.exists()}")
            if extractor.details_dir.exists():
                existing_files = list(extractor.details_dir.glob("*.txt"))
                print(f"ğŸ“ ç°æœ‰è¯¦æƒ…æ–‡ä»¶æ•°é‡: {len(existing_files)}")

            if clicked_count == 0:
                print("â„¹ï¸ æ²¡æœ‰å·²ç‚¹å‡»çš„å•†å“ï¼Œä½†ç»§ç»­æ‰§è¡Œè¯¦æƒ…é¡µæŠ“å–ï¼ˆå¯èƒ½æœ‰æ–°å•†å“ï¼‰")
                print("ğŸ”„ jiex.py ç»§ç»­æ‰§è¡Œ - æ£€æŸ¥é¡µé¢ä¸­çš„å•†å“")
                # ğŸ”¥ ä¿®å¤ï¼šä¸è·³è¿‡ï¼Œç»§ç»­æ‰§è¡Œä»¥å¤„ç†é¡µé¢ä¸­å¯èƒ½å­˜åœ¨çš„æ–°å•†å“

            # ğŸ”¥ ä¿®å¤ï¼šæ— è®ºæ˜¯å¦æœ‰å·²ç‚¹å‡»å•†å“éƒ½ç»§ç»­æ‰§è¡Œ
            # è¿æ¥åˆ°æµè§ˆå™¨
            from playwright.async_api import async_playwright
            from config_manager import ConfigManager

            config_mgr = ConfigManager()
            debug_port = config_mgr.get_debug_port()



            playwright = await async_playwright().start()
            browser = await playwright.chromium.connect_over_cdp(f"http://localhost:{debug_port}")

            if browser.contexts:
                context = browser.contexts[0]
                if context.pages:
                    page = context.pages[0]

                    print("[æˆåŠŸ] æµè§ˆå™¨è¿æ¥æˆåŠŸ")
                    print("ğŸ”„ å¼€å§‹å¤„ç†è¯¦æƒ…é¡µæ•°æ®...")

                    # ğŸ”¥ ä¿®å¤ï¼šä¼ é€’browser_idå‚æ•°
                    success = await extract_and_save(page, browser_id)

                    if success:
                        print("[æˆåŠŸ] è¯¦æƒ…é¡µæ•°æ®å¤„ç†å®Œæˆ")
                        # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºä¿å­˜ç»“æœ
                        details_dir = extractor.details_dir
                        if details_dir.exists():
                            saved_files = list(details_dir.glob("*.txt"))
                            print(f"ğŸ“ å·²ä¿å­˜è¯¦æƒ…æ–‡ä»¶æ•°é‡: {len(saved_files)}")
                            if saved_files:
                                latest_file = max(saved_files, key=lambda x: x.stat().st_mtime)
                                print(f"ğŸ“„ æœ€æ–°ä¿å­˜æ–‡ä»¶: {latest_file.name}")
                    else:
                        print("[é”™è¯¯] è¯¦æƒ…é¡µæ•°æ®å¤„ç†å¤±è´¥")
                else:
                    print("[é”™è¯¯] æ²¡æœ‰å¯ç”¨çš„é¡µé¢")
            else:
                print("[é”™è¯¯] æ²¡æœ‰å¯ç”¨çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡")

            await playwright.stop()

        except Exception as e:
            print(f"[é”™è¯¯] è¯¦æƒ…é¡µæ•°æ®æŠ“å–å¼‚å¸¸: {e}")
        finally:
            # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šæ— è®ºæˆåŠŸå¤±è´¥éƒ½è¦æ¸…é™¤ä»»åŠ¡çŠ¶æ€
            extractor.set_task_status("detail_running", False)

    except Exception as e:
        print(f"[é”™è¯¯] è¯¦æƒ…é¡µæ•°æ®æŠ“å–å¼‚å¸¸: {e}")


if __name__ == "__main__":
    import asyncio
    import sys

    async def parse_single_product(target_goods_id: str):

        try:
            # åˆ›å»ºæŠ“å–å™¨å®ä¾‹
            extractor = DetailPageExtractor()

            # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šç­‰å¾…ä¸Šä¸€ä¸ªä»»åŠ¡å®Œæˆ
            extractor.wait_for_previous_task()

            # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šè®¾ç½®å½“å‰ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
            extractor.set_task_status("detail_running", True)

            try:
                # è¿æ¥æµè§ˆå™¨å¹¶å¤„ç†è¯¦æƒ…é¡µ
                from playwright.async_api import async_playwright

                async with async_playwright() as playwright:
                    browser = await playwright.chromium.connect_over_cdp(
                        f"http://localhost:{extractor.config_mgr.get_debug_port()}"
                    )

                    if browser.contexts:
                        context = browser.contexts[0]
                        if context.pages:
                            # ğŸ”¥ ä¿®å¤ï¼šæ‰¾åˆ°æ­£ç¡®çš„è¯¦æƒ…é¡µé¢
                            detail_page = None

                            # éå†æ‰€æœ‰é¡µé¢ï¼Œæ‰¾åˆ°åŒ…å«å•†å“è¯¦æƒ…çš„é¡µé¢
                            for page in context.pages:
                                try:
                                    url = page.url
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹¼å¤šå¤šè¯¦æƒ…é¡µ
                                    if "yangkeduo.com" in url and "goods" in url:
                                        detail_page = page
                                        break
                                except Exception as e:
                                    print(f"[è­¦å‘Š] æ£€æŸ¥é¡µé¢å¤±è´¥: {e}")
                                    continue

                            # å¦‚æœæ²¡æ‰¾åˆ°è¯¦æƒ…é¡µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé¡µé¢
                            if not detail_page and context.pages:
                                detail_page = context.pages[0]

                            if detail_page:
                                # å¤„ç†å½“å‰é¡µé¢çš„è¯¦æƒ…æ•°æ®
                                success = await extractor.process_detail_page(detail_page, target_goods_id)
                            else:
                                print(f"[é”™è¯¯] æ²¡æœ‰å¯ç”¨çš„é¡µé¢")
                                success = False

                            if success:
                                print(f"[æˆåŠŸ] å•†å“ {target_goods_id} è§£ææˆåŠŸ")
                            else:
                                print(f"[é”™è¯¯] å•†å“ {target_goods_id} è§£æå¤±è´¥")
                        else:
                            print("[é”™è¯¯] æ²¡æœ‰å¯ç”¨çš„é¡µé¢")
                    else:
                        print("[é”™è¯¯] æ²¡æœ‰å¯ç”¨çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡")

                    await playwright.stop()

            finally:
                # ğŸ”¥ æ’é˜Ÿæœºåˆ¶ï¼šæ— è®ºæˆåŠŸå¤±è´¥éƒ½è¦æ¸…é™¤ä»»åŠ¡çŠ¶æ€
                extractor.set_task_status("detail_running", False)

        except Exception as e:
            print(f"[é”™è¯¯] å•å•†å“è§£æå¼‚å¸¸: {e}")

    # ğŸ”¥ æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼šå•†å“ID
    if len(sys.argv) > 1:
        goods_id = sys.argv[1]
        print(f"ğŸ¯ è§£æå•†å“: {goods_id}")
        asyncio.run(parse_single_product(goods_id))
    else:
        print("[é”™è¯¯] è¯·æä¾›å•†å“IDä½œä¸ºå‘½ä»¤è¡Œå‚æ•°")